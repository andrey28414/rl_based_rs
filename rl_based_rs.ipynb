{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d3150a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fba47cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, datapath, itempath):\n",
    "        self.data = self.load_datas(datapath, itempath)\n",
    "        self.users = self.data['userId'].unique()\n",
    "        self.items = self.data['itemId'].unique()\n",
    "        self.histo = self.gen_histo()\n",
    "        self.train = []\n",
    "        self.test = []\n",
    "\n",
    "    def load_datas(self, datapath, itempath):\n",
    "        data = pd.read_csv(datapath, sep='\\t', names=['userId', 'itemId', 'rating', 'timestamp'])\n",
    "        movie_titles = pd.read_csv(itempath, sep='|', names=['itemId', 'itemName'], usecols=range(2), encoding='latin-1')\n",
    "        return data.merge(movie_titles, on='itemId', how='left')\n",
    "\n",
    "    def gen_histo(self):\n",
    "        historic_users = []\n",
    "        for i, u in enumerate(self.users):\n",
    "            temp = self.data[self.data['userId'] == u]\n",
    "            temp = temp.sort_values('timestamp').reset_index()\n",
    "            temp.drop('index', axis=1, inplace=True)\n",
    "            historic_users.append(temp)\n",
    "        return historic_users\n",
    "\n",
    "    def sample_histo(self, user_histo, action_ratio=0.8, max_samp_by_user=5, max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
    "        n = len(user_histo)\n",
    "        sep = int(action_ratio * n)\n",
    "        nb_sample = random.randint(1, max_samp_by_user)\n",
    "        if not nb_states:\n",
    "            nb_states = [min(random.randint(1, sep), max_state) for i in range(nb_sample)]\n",
    "        if not nb_actions:\n",
    "            nb_actions = [min(random.randint(1, n - sep), max_action) for i in range(nb_sample)]\n",
    "        assert len(nb_states) == len(nb_actions), 'Given array must have the same size'\n",
    "\n",
    "        states = []\n",
    "        actions = []\n",
    "        for i in range(len(nb_states)):\n",
    "            sample_states = user_histo.iloc[0:sep].sample(nb_states[i])\n",
    "            sample_actions = user_histo.iloc[-(n - sep):].sample(nb_actions[i])\n",
    "\n",
    "            sample_state = []\n",
    "            sample_action = []\n",
    "            for j in range(nb_states[i]):\n",
    "                row = sample_states.iloc[j]\n",
    "                state = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
    "                sample_state.append(state)\n",
    "\n",
    "            for j in range(nb_actions[i]):\n",
    "                row = sample_actions.iloc[j]\n",
    "                action = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
    "                sample_action.append(action)\n",
    "\n",
    "            states.append(sample_state)\n",
    "            actions.append(sample_action)\n",
    "        return states, actions\n",
    "\n",
    "    def gen_train_test(self, test_ratio, seed=None):\n",
    "        n = len(self.histo)\n",
    "\n",
    "        if seed is not None:\n",
    "            random.Random(seed).shuffle(self.histo)\n",
    "        else:\n",
    "            random.shuffle(self.histo)\n",
    "\n",
    "        self.train = self.histo[:int((test_ratio * n))]\n",
    "        self.test = self.histo[int((test_ratio * n)):]\n",
    "        self.user_train = [h.iloc[0, 0] for h in self.train]\n",
    "        self.user_test = [h.iloc[0, 0] for h in self.test]\n",
    "\n",
    "    def write_csv(self, filename, histo_to_write, delimiter=';', action_ratio=0.8, max_samp_by_user=5, max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
    "        with open(filename, mode='w') as file:\n",
    "            f_writer = csv.writer(file, delimiter=delimiter)\n",
    "            f_writer.writerow(['state', 'action_reward', 'n_state'])\n",
    "            for user_histo in histo_to_write:\n",
    "                states, actions = self.sample_histo(user_histo, action_ratio, max_samp_by_user, max_state, max_action, nb_states, nb_actions)\n",
    "                for i in range(len(states)):\n",
    "                    state_str = '|'.join(states[i])\n",
    "                    action_str = '|'.join(actions[i])\n",
    "                    n_state_str = state_str + '|' + action_str\n",
    "                    f_writer.writerow([state_str, action_str, n_state_str])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87be553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsGenerator:\n",
    "    def __init__(self, train_users, data):\n",
    "        self.train_users = train_users\n",
    "\n",
    "        self.data = data.sort_values(by=['timestamp'])\n",
    "        self.data['userId'] = self.data['userId'] - 1\n",
    "        self.data['itemId'] = self.data['itemId'] - 1\n",
    "        self.user_count = self.data['userId'].max() + 1\n",
    "        self.movie_count = self.data['itemId'].max() + 1\n",
    "        self.user_movies = {} \n",
    "        for userId in range(self.user_count):\n",
    "            self.user_movies[userId] = self.data[self.data.userId == userId]['itemId'].tolist()\n",
    "        self.m = self.model()\n",
    "\n",
    "    def model(self, hidden_layer_size=100):\n",
    "        m = Sequential()\n",
    "        m.add(Dense(hidden_layer_size, input_shape=(1, self.movie_count)))\n",
    "        m.add(Dropout(0.2))\n",
    "        m.add(Dense(self.movie_count, activation='softmax'))\n",
    "        m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return m\n",
    "\n",
    "    def generate_input(self, user_id):\n",
    "        user_movies_count = len(self.user_movies[user_id])\n",
    "        random_index = np.random.randint(0, user_movies_count - 1)  \n",
    "        target = np.zeros((1, self.movie_count))\n",
    "        target[0][self.user_movies[user_id][random_index]] = 1\n",
    "        context = np.zeros((1, self.movie_count))\n",
    "        context[0][self.user_movies[user_id][:random_index] + self.user_movies[user_id][random_index + 1:]] = 1\n",
    "        return context, target\n",
    "\n",
    "    def train(self, nb_epochs=300, batch_size=10000):\n",
    "        for i in range(nb_epochs):\n",
    "            print('%d/%d' % (i + 1, nb_epochs))\n",
    "            batch = [self.generate_input(user_id=np.random.choice(self.train_users) - 1) for _ in range(batch_size)]\n",
    "            X_train = np.array([b[0] for b in batch])\n",
    "            y_train = np.array([b[1] for b in batch])\n",
    "            self.m.fit(X_train, y_train, epochs=1, validation_split=0.5)\n",
    "\n",
    "    def test(self, test_users, batch_size=100000):\n",
    "        batch_test = [self.generate_input(user_id=np.random.choice(test_users) - 1) for _ in range(batch_size)]\n",
    "        X_test = np.array([b[0] for b in batch_test])\n",
    "        y_test = np.array([b[1] for b in batch_test])\n",
    "        return self.m.evaluate(X_test, y_test)\n",
    "\n",
    "    def save_embeddings(self, file_name):\n",
    "        inp = self.m.input  \n",
    "        outputs = [layer.output for layer in self.m.layers] \n",
    "        functor = K.function([inp, K.learning_phase()], outputs) \n",
    "\n",
    "        vectors = []\n",
    "        for movie_id in range(self.movie_count):\n",
    "            movie = np.zeros((1, 1, self.movie_count))\n",
    "            movie[0][0][movie_id] = 1\n",
    "            layer_outs = functor([movie])\n",
    "            vector = [str(v) for v in layer_outs[0][0][0]]\n",
    "            vector = '|'.join(vector)\n",
    "            vectors.append([movie_id, vector])\n",
    "\n",
    "        embeddings = pd.DataFrame(vectors, columns=['item_id', 'vectors']).astype({'item_id': 'int32'})\n",
    "        embeddings.to_csv(file_name, sep=';', index=False)\n",
    "        files.download(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0002af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "    def __init__(self, item_embeddings):\n",
    "        self.item_embeddings = item_embeddings\n",
    "\n",
    "    def size(self):\n",
    "        return self.item_embeddings.shape[1]\n",
    "\n",
    "    def get_embedding_vector(self):\n",
    "        return self.item_embeddings\n",
    "\n",
    "    def get_embedding(self, item_index):\n",
    "        return self.item_embeddings[item_index]\n",
    "\n",
    "    def embed(self, item_list):\n",
    "        return np.array([self.get_embedding(item-1) for item in item_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ae75d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(data_path):\n",
    "    data = pd.read_csv(data_path, sep=';')\n",
    "    for col in ['state', 'n_state', 'action_reward']:\n",
    "        data[col] = [np.array([[np.int_(k) for k in ee.split('&')] for ee in e.split('|')]) for e in data[col]]\n",
    "    for col in ['state', 'n_state']:\n",
    "        data[col] = [np.array([e[0] for e in l]) for l in data[col]]\n",
    "\n",
    "    data['action'] = [[e[0] for e in l] for l in data['action_reward']]\n",
    "    data['reward'] = [tuple(e[1] for e in l) for l in data['action_reward']]\n",
    "    data.drop(columns=['action_reward'], inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_embeddings(embeddings_path):  \n",
    "    embeddings = pd.read_csv(embeddings_path, sep=';')\n",
    "\n",
    "    return np.array([[np.float64(k) for k in e.split('|')] for e in embeddings['vectors']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62944045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self, data, embeddings, alpha, gamma, fixed_length):\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        self.embedded_data = pd.DataFrame()\n",
    "        self.embedded_data['state'] = [np.array([embeddings.get_embedding(item_id) \n",
    "            for item_id in row['state']]) for _, row in data.iterrows()]\n",
    "        self.embedded_data['action'] = [np.array([embeddings.get_embedding(item_id) \n",
    "            for item_id in row['action']]) for _, row in data.iterrows()]\n",
    "        self.embedded_data['reward'] = data['reward']\n",
    "\n",
    "        self.alpha = alpha \n",
    "        self.gamma = gamma\n",
    "        self.fixed_length = fixed_length\n",
    "        self.current_state = self.reset()\n",
    "        self.groups = self.get_groups()\n",
    "\n",
    "    def reset(self):\n",
    "        self.init_state = self.embedded_data['state'].sample(1).values[0]\n",
    "        return self.init_state\n",
    "\n",
    "    def step(self, actions):\n",
    "\n",
    "\n",
    "        simulated_rewards, cumulated_reward = self.simulate_rewards(\n",
    "            self.current_state.reshape((1, -1)), actions.reshape((1, -1))\n",
    "        )\n",
    "\n",
    "        for k in range(len(simulated_rewards)): \n",
    "            if simulated_rewards[k] > 0: \n",
    "                self.current_state = np.append(self.current_state, [actions[k]], axis=0)\n",
    "                if self.fixed_length: \n",
    "                    self.current_state = np.delete(self.current_state, 0, axis=0)\n",
    "\n",
    "        return cumulated_reward, self.current_state\n",
    "\n",
    "    def get_groups(self):\n",
    "\n",
    "        groups = []\n",
    "        for rewards, group in self.embedded_data.groupby(['reward']):\n",
    "            size = group.shape[0]\n",
    "            states = np.array(list(group['state'].values))\n",
    "            actions = np.array(list(group['action'].values))\n",
    "            groups.append({\n",
    "                'size': size, \n",
    "                'rewards': rewards[0], \n",
    "                'average state': (np.sum(states / np.linalg.norm(states, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)), \n",
    "                'average action': (np.sum(actions / np.linalg.norm(actions, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)) \n",
    "            })\n",
    "        return groups\n",
    "\n",
    "    def simulate_rewards(self, current_state, chosen_actions, reward_type='grouped cosine'):\n",
    "\n",
    "        def cosine_state_action(s_t, a_t, s_i, a_i):\n",
    "            cosine_state = np.dot(s_t, s_i.T) / (np.linalg.norm(s_t, 2) * np.linalg.norm(s_i, 2))\n",
    "            cosine_action = np.dot(a_t, a_i.T) / (np.linalg.norm(a_t, 2) * np.linalg.norm(a_i, 2))\n",
    "            return (self.alpha * cosine_state + (1 - self.alpha) * cosine_action).reshape((1,))\n",
    "\n",
    "        if reward_type == 'normal':\n",
    "            probabilities = [cosine_state_action(current_state, chosen_actions, row['state'], row['action'])\n",
    "                for _, row in self.embedded_data.iterrows()]\n",
    "        elif reward_type == 'grouped average':\n",
    "            probabilities = np.array([g['size'] for g in self.groups]) *\\\n",
    "                [(self.alpha * (np.dot(current_state, g['average state'].T) / np.linalg.norm(current_state, 2))\\\n",
    "                + (1 - self.alpha) * (np.dot(chosen_actions, g['average action'].T) / np.linalg.norm(chosen_actions, 2)))\n",
    "                for g in self.groups]\n",
    "        elif reward_type == 'grouped cosine':\n",
    "            probabilities = [cosine_state_action(current_state, chosen_actions, g['average state'], g['average action'])\n",
    "                for g in self.groups]\n",
    "\n",
    "        probabilities = np.array(probabilities) / sum(probabilities)\n",
    "\n",
    "        if reward_type == 'normal':\n",
    "            returned_rewards = self.embedded_data.iloc[np.argmax(probabilities)]['reward']\n",
    "        elif reward_type in ['grouped average', 'grouped cosine']:\n",
    "            returned_rewards = self.groups[np.argmax(probabilities)]['rewards']\n",
    "\n",
    "        def overall_reward(rewards, gamma):\n",
    "            return np.sum([gamma**k * reward for k, reward in enumerate(rewards)])\n",
    "\n",
    "        if reward_type in ['normal', 'grouped average']:\n",
    "            cumulated_reward = overall_reward(returned_rewards, self.gamma)\n",
    "        elif reward_type == 'grouped cosine':\n",
    "            cumulated_reward = np.sum([p * overall_reward(g['rewards'], self.gamma)\n",
    "                for p, g in zip(probabilities, self.groups)])\n",
    "\n",
    "        return returned_rewards, cumulated_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d07e51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor():\n",
    "    def __init__(self, sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embedding_size, tau, learning_rate, net_name, scope='actor'):\n",
    "        self.sess = sess\n",
    "        self.state_space_size = state_space_size\n",
    "        self.action_space_size = action_space_size\n",
    "        self.batch_size = batch_size\n",
    "        self.ra_length = ra_length\n",
    "        self.history_length = history_length\n",
    "        self.embedding_size = embedding_size\n",
    "        self.tau = tau\n",
    "        self.learning_rate = learning_rate\n",
    "        self.scope = scope\n",
    "\n",
    "        with tf.variable_scope(self.scope):\n",
    "            self.action_weights, self.state, self.sequence_length = self._build_net('estimator_'+net_name)\n",
    "            self.network_params = tf.trainable_variables()\n",
    "\n",
    "            self.target_action_weights, self.target_state, self.target_sequence_length = self._build_net('target_'+net_name)\n",
    "            self.target_network_params = tf.trainable_variables()[len(self.network_params):]\n",
    "\n",
    "            self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
    "                                                for i in range(len(self.target_network_params))]\n",
    "\n",
    "            self.update_target_network_params = [self.target_network_params[i].assign(\n",
    "                tf.multiply(self.tau, self.network_params[i]) +\n",
    "                tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
    "                for i in range(len(self.target_network_params))]\n",
    "\n",
    "            self.action_gradients = tf.placeholder(tf.float32, [None, self.action_space_size])\n",
    "            gradients = tf.gradients(tf.reshape(self.action_weights, [self.batch_size, self.action_space_size]),\n",
    "                                     self.network_params, self.action_gradients)\n",
    "            params_gradients = list(map(lambda x: tf.div(x, self.batch_size * self.action_space_size),\n",
    "                                        gradients))\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).apply_gradients(\n",
    "                zip(params_gradients, self.network_params))\n",
    "\n",
    "    def _build_net(self, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            \n",
    "            state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
    "            state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
    "            sequence_length = tf.placeholder(tf.int32, [None], 'sequence_length')\n",
    "            \n",
    "            transposed_tensor = tf.transpose(state_, perm=[0, 2, 1])\n",
    "            dense_tensor = tf.keras.layers.Dense(transposed_tensor.shape[-1], activation=tf.nn.relu)(transposed_tensor)\n",
    "            dense_tensor = tf.keras.layers.Dropout(rate=0.2)(dense_tensor)\n",
    "            dense_tensor = tf.transpose(dense_tensor, perm=[0, 2, 1])\n",
    "            \n",
    "            dense_tensor = tf.keras.layers.BatchNormalization()(dense_tensor)\n",
    "            dense_tensor = tf.keras.layers.Dense(dense_tensor.shape[-1], activation=tf.nn.relu)(dense_tensor)\n",
    "            dense_tensor = tf.keras.layers.Dropout(rate=0.2)(dense_tensor)\n",
    "            \n",
    "            dense_tensor = tf.reshape(dense_tensor, [-1, self.state_space_size])\n",
    "            \n",
    "            outputs = tf.keras.layers.Dense(512,activation='relu')(dense_tensor)\n",
    "            outputs = tf.keras.layers.Dense(256,activation='relu')(outputs)\n",
    "            outputs = tf.keras.layers.Dense(self.action_space_size)(outputs)\n",
    "            action_weights = tf.reshape(outputs, [-1, self.ra_length, self.embedding_size])\n",
    "            \n",
    "        return action_weights, state, sequence_length\n",
    "\n",
    "    def train(self, state, sequence_length, action_gradients):\n",
    "        self.sess.run(self.optimizer,\n",
    "                      feed_dict={\n",
    "                          self.state: state,\n",
    "                          self.sequence_length: sequence_length,\n",
    "                          self.action_gradients: action_gradients})\n",
    "\n",
    "    def predict(self, state, sequence_length):\n",
    "        return self.sess.run(self.action_weights,\n",
    "                             feed_dict={\n",
    "                                 self.state: state,\n",
    "                                 self.sequence_length: sequence_length})\n",
    "\n",
    "    def predict_target(self, state, sequence_length):\n",
    "        return self.sess.run(self.target_action_weights,\n",
    "                             feed_dict={\n",
    "                                 self.target_state: state,\n",
    "                                 self.target_sequence_length: sequence_length})\n",
    "\n",
    "    def init_target_network(self):\n",
    "        self.sess.run(self.init_target_network_params)\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.sess.run(self.update_target_network_params)\n",
    "\n",
    "    def get_recommendation_list(self, ra_length, noisy_state, embeddings, target=False):\n",
    "\n",
    "        def get_score(weights, embedding, batch_size):\n",
    "            ret = np.dot(weights, embedding.T)\n",
    "            return ret\n",
    "\n",
    "        batch_size = noisy_state.shape[0]\n",
    "        method = self.predict_target if target else self.predict\n",
    "        weights = method(noisy_state, [ra_length] * batch_size)\n",
    "\n",
    "        scores = np.array([[[get_score(weights[i][k], embedding, batch_size)\n",
    "                            for embedding in embeddings.get_embedding_vector()]\n",
    "                            for k in range(ra_length)]\n",
    "                           for i in range(batch_size)])\n",
    "        return np.array([[embeddings.get_embedding(np.argmax(scores[i][k]))\n",
    "                          for k in range(ra_length)]\n",
    "                         for i in range(batch_size)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5034b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic():\n",
    "    def __init__(self, sess, state_space_size, action_space_size, history_length, embedding_size, tau, learning_rate, net_name, scope='critic'):\n",
    "        self.sess = sess\n",
    "        self.state_space_size = state_space_size\n",
    "        self.action_space_size = action_space_size\n",
    "        self.history_length = history_length\n",
    "        self.embedding_size = embedding_size\n",
    "        self.tau = tau\n",
    "        self.learning_rate = learning_rate\n",
    "        self.scope = scope\n",
    "\n",
    "        with tf.variable_scope(self.scope):\n",
    "            self.critic_Q_value, self.state, self.action, self.sequence_length = self._build_net('estimator_'+net_name)\n",
    "            self.network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='estimator_'+net_name)\n",
    "\n",
    "            self.target_Q_value, self.target_state, self.target_action, self.target_sequence_length = self._build_net('target_'+net_name)\n",
    "            self.target_network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target_'+net_name)\n",
    "\n",
    "            self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
    "                                                for i in range(len(self.target_network_params))]\n",
    "\n",
    "            self.update_target_network_params = [self.target_network_params[i].assign(\n",
    "                                                    tf.multiply(self.tau, self.network_params[i]) +\n",
    "                                                    tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
    "                                                    for i in range(len(self.target_network_params))]\n",
    "\n",
    "            self.expected_reward = tf.placeholder(tf.float32, [None, 1])\n",
    "            self.loss = tf.reduce_mean(tf.squared_difference(self.expected_reward, self.critic_Q_value))\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "            self.action_gradients = tf.gradients(self.critic_Q_value, self.action)\n",
    "\n",
    "    def _build_net(self, scope):\n",
    "        def gather_last_output(data, seq_lens):\n",
    "            def cli_value(x, v):\n",
    "                y = tf.constant(v, shape=x.get_shape(), dtype=tf.int64)\n",
    "                return tf.where(tf.greater(x, y), x, y)\n",
    "\n",
    "            this_range = tf.range(tf.cast(tf.shape(seq_lens)[0], dtype=tf.int64), dtype=tf.int64)\n",
    "            tmp_end = tf.map_fn(lambda x: cli_value(x, 0), seq_lens - 1, dtype=tf.int64)\n",
    "            indices = tf.stack([this_range, tmp_end], axis=1)\n",
    "            return tf.gather_nd(data, indices)\n",
    "\n",
    "        with tf.variable_scope(scope):\n",
    "            state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
    "            state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
    "            action = tf.placeholder(tf.float32, [None, self.action_space_size], 'action')\n",
    "            sequence_length = tf.placeholder(tf.int64, [None], name='critic_sequence_length')\n",
    "            inputs = tf.concat([state, action], axis=-1)\n",
    "            inputs = tf.layers.Dense(self.state_space_size, activation=tf.nn.relu)(inputs)\n",
    "            inputs = tf.layers.Dense(1024, activation=tf.nn.relu)(inputs)\n",
    "            inputs = tf.layers.Dense(512, activation=tf.nn.relu)(inputs)\n",
    "            inputs = tf.layers.Dense(128, activation=tf.nn.relu)(inputs)\n",
    "            inputs = tf.layers.Dense(32, activation=tf.nn.relu)(inputs)\n",
    "            inputs = tf.layers.Dense(16, activation=tf.nn.relu)(inputs)\n",
    "            critic_Q_value = tf.layers.Dense(1)(inputs)\n",
    "            return critic_Q_value, state, action, sequence_length\n",
    "\n",
    "    def train(self, state, action, sequence_length, expected_reward):\n",
    "        return self.sess.run([self.critic_Q_value, self.loss, self.optimizer],\n",
    "                                feed_dict={\n",
    "                                    self.state: state,\n",
    "                                    self.action: action,\n",
    "                                    self.sequence_length: sequence_length,\n",
    "                                    self.expected_reward: expected_reward})\n",
    "\n",
    "    def predict(self, state, action, sequence_length):\n",
    "        return self.sess.run(self.critic_Q_value,\n",
    "                                feed_dict={\n",
    "                                    self.state: state,\n",
    "                                    self.action: action,\n",
    "                                    self.sequence_length: sequence_length})\n",
    "\n",
    "    def predict_target(self, state, action, sequence_length):\n",
    "        return self.sess.run(self.target_Q_value,\n",
    "                                feed_dict={\n",
    "                                    self.target_state: state,\n",
    "                                    self.target_action: action,\n",
    "                                    self.target_sequence_length: sequence_length})\n",
    "\n",
    "    def get_action_gradients(self, state, action, sequence_length):\n",
    "        return np.array(self.sess.run(self.action_gradients,\n",
    "                                feed_dict={\n",
    "                                    self.state: state,\n",
    "                                    self.action: action,\n",
    "                                    self.sequence_length: sequence_length})[0])\n",
    "\n",
    "    def init_target_network(self):\n",
    "        self.sess.run(self.init_target_network_params)\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.sess.run(self.update_target_network_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4627f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer = []\n",
    "\n",
    "    def add(self, state, action, reward, n_state):\n",
    "        self.buffer.append([state, action, reward, n_state])\n",
    "        if len(self.buffer) > self.buffer_size:\n",
    "            self.buffer.pop(0)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8489a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_replay_td3(replay_memory, batch_size, actor, critic1, critic2, embeddings, ra_length, state_space_size, action_space_size, discount_factor):\n",
    "\n",
    "    samples = replay_memory.sample_batch(batch_size)\n",
    "    states = np.array([s[0] for s in samples])\n",
    "    actions = np.array([s[1] for s in samples])\n",
    "    rewards = np.array([s[2] for s in samples])\n",
    "    n_states = np.array([s[3] for s in samples]).reshape(-1, state_space_size)\n",
    "\n",
    "    n_actions = actor.get_recommendation_list(ra_length, states, embeddings, target=True).reshape(-1, action_space_size)\n",
    "\n",
    "    target_Q_value = np.minimum(critic1.predict_target(n_states, n_actions, [ra_length] * batch_size),critic2.predict_target(n_states, n_actions, [ra_length] * batch_size))\n",
    "\n",
    "    expected_rewards = rewards + discount_factor * target_Q_value\n",
    "\n",
    "    critic_Q_value1, critic_loss1, _ = critic1.train(states, actions, [ra_length] * batch_size, expected_rewards)\n",
    "    critic_Q_value2, critic_loss2, _ = critic2.train(states, actions, [ra_length] * batch_size, expected_rewards)\n",
    "\n",
    "    action_gradients = critic1.get_action_gradients(states, n_actions, [ra_length] * batch_size)\n",
    "    actor.train(states, [ra_length] * batch_size, action_gradients)\n",
    "\n",
    "    critic1.update_target_network()\n",
    "    critic2.update_target_network()\n",
    "\n",
    "    actor.update_target_network()\n",
    "\n",
    "    return np.amax(critic_Q_value1), critic_loss1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f160df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrnsteinUhlenbeckNoise:\n",
    "    def __init__(self, action_space_size, mu=0, theta=0.5, sigma=0.2):\n",
    "        self.action_space_size = action_space_size\n",
    "        self.mu = mu\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.state = np.ones(self.action_space_size) * self.mu\n",
    "\n",
    "    def get(self):\n",
    "        self.state += self.theta * (self.mu - self.state) + self.sigma * np.random.rand(self.action_space_size)\n",
    "        return self.state\n",
    "\n",
    "\n",
    "def train_td3(sess, environment, actor, critic1, critic2, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary):\n",
    "    def build_summaries():\n",
    "        episode_reward = tf.Variable(0.)\n",
    "        tf.summary.scalar('reward', episode_reward)\n",
    "        episode_max_Q = tf.Variable(0.)\n",
    "        tf.summary.scalar('max_Q_value', episode_max_Q)\n",
    "        critic_loss = tf.Variable(0.)\n",
    "        tf.summary.scalar('critic_loss', critic_loss)\n",
    "\n",
    "        summary_vars = [episode_reward, episode_max_Q, critic_loss]\n",
    "        summary_ops = tf.summary.merge_all()\n",
    "        return summary_ops, summary_vars\n",
    "\n",
    "    summary_ops, summary_vars = build_summaries()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(filename_summary, sess.graph)\n",
    "\n",
    "    actor.init_target_network()\n",
    "    critic1.init_target_network()\n",
    "    critic2.init_target_network()\n",
    "\n",
    "    replay_memory = ReplayMemory(buffer_size) \n",
    "    replay = False\n",
    "    q_values = []\n",
    "    time_seq = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i_session in range(nb_episodes): \n",
    "        session_reward = 0\n",
    "        session_Q_value = 0\n",
    "        session_critic_loss = 0\n",
    "        session_q_values = []\n",
    "\n",
    "\n",
    "        states = environment.reset() \n",
    "        \n",
    "        if (i_session + 1) % 10 == 0:\n",
    "            environment.groups = environment.get_groups()\n",
    "          \n",
    "        exploration_noise = OrnsteinUhlenbeckNoise(history_length * embeddings.size())\n",
    "\n",
    "        for t in range(nb_rounds):\n",
    "            actions = actor.get_recommendation_list(\n",
    "                ra_length,\n",
    "                np.clip(states.reshape(1, -1)+ exploration_noise.get().reshape(1, -1),a_min=0,a_max=1),\n",
    "                embeddings).reshape(ra_length, embeddings.size())\n",
    "\n",
    "            rewards, next_states = environment.step(actions)\n",
    "\n",
    "            replay_memory.add(states.reshape(history_length * embeddings.size()),\n",
    "                            actions.reshape(ra_length * embeddings.size()),\n",
    "                            [rewards],\n",
    "                            next_states.reshape(history_length * embeddings.size()))\n",
    "\n",
    "            states = next_states \n",
    "\n",
    "            session_reward += rewards\n",
    "            \n",
    "            if replay_memory.size() >= batch_size:\n",
    "                replay = True\n",
    "                replay_Q_value, critic_loss = experience_replay_td3(replay_memory, batch_size,\n",
    "                actor, critic1, critic2, embeddings, ra_length, history_length * embeddings.size(),\n",
    "                ra_length * embeddings.size(), discount_factor)\n",
    "                session_Q_value += replay_Q_value\n",
    "                session_q_values.append(replay_Q_value)\n",
    "                session_critic_loss += critic_loss\n",
    "\n",
    "            summary_str = sess.run(summary_ops,\n",
    "                                 feed_dict={summary_vars[0]: session_reward,\n",
    "                                            summary_vars[1]: session_Q_value,\n",
    "                                            summary_vars[2]: session_critic_loss})\n",
    "          \n",
    "            writer.add_summary(summary_str, i_session)\n",
    "\n",
    "        q_values.append(session_q_values)\n",
    "        str_loss = str('Loss=%0.4f' % session_critic_loss)\n",
    "        print(('Episode %d/%d Reward=%d Q_value=%d Time=%ds ' + (str_loss if replay else 'No replay')) % (i_session + 1, nb_episodes, session_reward, session_Q_value, time.time() - start_time))\n",
    "        time_seq.append(time.time())\n",
    "        start_time = time.time()\n",
    "\n",
    "    writer.close()\n",
    "    tf.train.Saver().save(sess, 'models.h5', write_meta_graph=False)\n",
    "    return q_values, time_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c7d24e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_length = 12\n",
    "ra_length = 4 \n",
    "discount_factor = 0.99\n",
    "actor_lr = 0.0001\n",
    "critic_lr = 0.001\n",
    "tau = 0.001 \n",
    "batch_size = 64\n",
    "nb_rounds = 50\n",
    "filename_summary = 'summary.txt'\n",
    "alpha = 0.5 \n",
    "gamma = 0.9 \n",
    "buffer_size = 1000000 \n",
    "fixed_length = True \n",
    "\n",
    "dg = DataGenerator('ml-100k/u.data', 'ml-100k/u.item')\n",
    "dg.gen_train_test(0.8, seed=42)\n",
    "\n",
    "dg.write_csv('train.csv', dg.train, nb_states=[history_length], nb_actions=[ra_length])\n",
    "dg.write_csv('test.csv', dg.test, nb_states=[history_length], nb_actions=[ra_length])\n",
    "\n",
    "data = read_file('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ffadacf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/300\n",
      "157/157 [==============================] - 2s 7ms/step - loss: 6.8971 - accuracy: 0.0084 - val_loss: 6.5796 - val_accuracy: 0.0138\n",
      "2/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 6.4579 - accuracy: 0.0140 - val_loss: 6.3414 - val_accuracy: 0.0132\n",
      "3/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 6.2991 - accuracy: 0.0112 - val_loss: 6.2116 - val_accuracy: 0.0186\n",
      "4/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 6.2035 - accuracy: 0.0194 - val_loss: 6.1336 - val_accuracy: 0.0162\n",
      "5/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 6.2024 - accuracy: 0.0168 - val_loss: 6.0736 - val_accuracy: 0.0208\n",
      "6/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 6.0759 - accuracy: 0.0220 - val_loss: 6.0466 - val_accuracy: 0.0192\n",
      "7/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 6.0739 - accuracy: 0.0238 - val_loss: 6.0078 - val_accuracy: 0.0218\n",
      "8/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 6.0047 - accuracy: 0.0258 - val_loss: 5.9152 - val_accuracy: 0.0276\n",
      "9/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 6.0364 - accuracy: 0.0238 - val_loss: 5.8799 - val_accuracy: 0.0254\n",
      "10/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 5.9655 - accuracy: 0.0236 - val_loss: 5.9182 - val_accuracy: 0.0242\n",
      "11/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 5.9198 - accuracy: 0.0252 - val_loss: 5.8611 - val_accuracy: 0.0276\n",
      "12/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.9194 - accuracy: 0.0284 - val_loss: 5.8321 - val_accuracy: 0.0368\n",
      "13/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.9193 - accuracy: 0.0272 - val_loss: 5.8810 - val_accuracy: 0.0366\n",
      "14/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.9103 - accuracy: 0.0318 - val_loss: 5.8110 - val_accuracy: 0.0394\n",
      "15/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.8276 - accuracy: 0.0344 - val_loss: 5.7975 - val_accuracy: 0.0388\n",
      "16/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.8449 - accuracy: 0.0376 - val_loss: 5.7508 - val_accuracy: 0.0448\n",
      "17/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.8091 - accuracy: 0.0356 - val_loss: 5.7309 - val_accuracy: 0.0452\n",
      "18/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.8106 - accuracy: 0.0364 - val_loss: 5.7399 - val_accuracy: 0.0496\n",
      "19/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.7871 - accuracy: 0.0432 - val_loss: 5.6655 - val_accuracy: 0.0506\n",
      "20/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.7659 - accuracy: 0.0406 - val_loss: 5.6461 - val_accuracy: 0.0558\n",
      "21/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.7300 - accuracy: 0.0470 - val_loss: 5.6188 - val_accuracy: 0.0516\n",
      "22/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 5.7066 - accuracy: 0.0472 - val_loss: 5.5939 - val_accuracy: 0.0638\n",
      "23/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.6462 - accuracy: 0.0518 - val_loss: 5.5732 - val_accuracy: 0.0614\n",
      "24/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 5.6315 - accuracy: 0.0636 - val_loss: 5.5231 - val_accuracy: 0.0758\n",
      "25/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 5.6052 - accuracy: 0.0652 - val_loss: 5.5562 - val_accuracy: 0.0692\n",
      "26/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.6346 - accuracy: 0.0588 - val_loss: 5.4790 - val_accuracy: 0.0792\n",
      "27/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.5440 - accuracy: 0.0658 - val_loss: 5.4576 - val_accuracy: 0.0884\n",
      "28/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.5524 - accuracy: 0.0684 - val_loss: 5.4741 - val_accuracy: 0.0854\n",
      "29/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.5148 - accuracy: 0.0732 - val_loss: 5.4695 - val_accuracy: 0.0862\n",
      "30/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.5328 - accuracy: 0.0756 - val_loss: 5.3910 - val_accuracy: 0.0926\n",
      "31/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.4762 - accuracy: 0.0810 - val_loss: 5.3424 - val_accuracy: 0.1030\n",
      "32/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.4607 - accuracy: 0.0836 - val_loss: 5.3096 - val_accuracy: 0.1060\n",
      "33/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.4334 - accuracy: 0.0866 - val_loss: 5.2997 - val_accuracy: 0.1026\n",
      "34/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.3798 - accuracy: 0.0898 - val_loss: 5.2350 - val_accuracy: 0.1138\n",
      "35/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.3621 - accuracy: 0.0950 - val_loss: 5.2198 - val_accuracy: 0.1246\n",
      "36/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.3131 - accuracy: 0.1020 - val_loss: 5.1902 - val_accuracy: 0.1180\n",
      "37/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.3111 - accuracy: 0.1010 - val_loss: 5.1621 - val_accuracy: 0.1234\n",
      "38/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.3109 - accuracy: 0.1058 - val_loss: 5.1258 - val_accuracy: 0.1372\n",
      "39/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.2204 - accuracy: 0.1130 - val_loss: 5.0890 - val_accuracy: 0.1338\n",
      "40/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 5.1794 - accuracy: 0.1152 - val_loss: 5.0596 - val_accuracy: 0.1462\n",
      "41/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.1331 - accuracy: 0.1232 - val_loss: 5.0142 - val_accuracy: 0.1468\n",
      "42/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 5.1092 - accuracy: 0.1258 - val_loss: 5.0068 - val_accuracy: 0.1608\n",
      "43/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.1007 - accuracy: 0.1298 - val_loss: 4.8940 - val_accuracy: 0.1714\n",
      "44/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.0384 - accuracy: 0.1326 - val_loss: 4.9103 - val_accuracy: 0.1738\n",
      "45/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 5.0602 - accuracy: 0.1414 - val_loss: 4.9096 - val_accuracy: 0.1710\n",
      "46/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.9790 - accuracy: 0.1458 - val_loss: 4.8364 - val_accuracy: 0.1850\n",
      "47/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.9735 - accuracy: 0.1510 - val_loss: 4.7864 - val_accuracy: 0.2032\n",
      "48/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.8862 - accuracy: 0.1574 - val_loss: 4.6942 - val_accuracy: 0.2174\n",
      "49/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.9274 - accuracy: 0.1624 - val_loss: 4.7606 - val_accuracy: 0.2036\n",
      "50/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.8655 - accuracy: 0.1692 - val_loss: 4.6982 - val_accuracy: 0.2090\n",
      "51/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.8119 - accuracy: 0.1754 - val_loss: 4.6645 - val_accuracy: 0.2094\n",
      "52/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.7805 - accuracy: 0.1786 - val_loss: 4.6284 - val_accuracy: 0.2256\n",
      "53/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 4.7148 - accuracy: 0.1874 - val_loss: 4.5611 - val_accuracy: 0.2390\n",
      "54/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.6724 - accuracy: 0.1914 - val_loss: 4.5542 - val_accuracy: 0.2478\n",
      "55/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.6770 - accuracy: 0.1970 - val_loss: 4.4957 - val_accuracy: 0.2396\n",
      "56/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.6886 - accuracy: 0.1980 - val_loss: 4.4954 - val_accuracy: 0.2458\n",
      "57/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.5292 - accuracy: 0.2162 - val_loss: 4.4729 - val_accuracy: 0.2588\n",
      "58/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.5759 - accuracy: 0.2054 - val_loss: 4.3520 - val_accuracy: 0.2730\n",
      "59/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.4829 - accuracy: 0.2240 - val_loss: 4.3767 - val_accuracy: 0.2734\n",
      "60/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.5022 - accuracy: 0.2204 - val_loss: 4.2913 - val_accuracy: 0.2902\n",
      "61/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.4180 - accuracy: 0.2368 - val_loss: 4.2362 - val_accuracy: 0.2944\n",
      "62/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 4.3245 - accuracy: 0.2502 - val_loss: 4.1907 - val_accuracy: 0.3000\n",
      "63/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 4.3623 - accuracy: 0.2472 - val_loss: 4.1213 - val_accuracy: 0.3122\n",
      "64/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 4.3071 - accuracy: 0.2584 - val_loss: 4.0901 - val_accuracy: 0.3208\n",
      "65/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.2645 - accuracy: 0.2594 - val_loss: 4.0507 - val_accuracy: 0.3252\n",
      "66/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.2565 - accuracy: 0.2668 - val_loss: 4.0000 - val_accuracy: 0.3484\n",
      "67/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.2075 - accuracy: 0.2766 - val_loss: 3.9337 - val_accuracy: 0.3506\n",
      "68/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.1309 - accuracy: 0.2802 - val_loss: 3.9833 - val_accuracy: 0.3528\n",
      "69/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 4.1151 - accuracy: 0.2916 - val_loss: 3.8735 - val_accuracy: 0.3740\n",
      "70/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.0379 - accuracy: 0.3078 - val_loss: 3.8974 - val_accuracy: 0.3706\n",
      "71/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 4.0128 - accuracy: 0.3120 - val_loss: 3.7387 - val_accuracy: 0.3894\n",
      "72/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.9783 - accuracy: 0.3126 - val_loss: 3.7011 - val_accuracy: 0.4010\n",
      "73/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.9427 - accuracy: 0.3142 - val_loss: 3.6515 - val_accuracy: 0.4076\n",
      "74/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.8817 - accuracy: 0.3314 - val_loss: 3.6419 - val_accuracy: 0.4054\n",
      "75/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 3.8636 - accuracy: 0.3324 - val_loss: 3.5569 - val_accuracy: 0.4300\n",
      "76/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 3.7597 - accuracy: 0.3574 - val_loss: 3.5433 - val_accuracy: 0.4312\n",
      "77/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 3.7911 - accuracy: 0.3412 - val_loss: 3.4058 - val_accuracy: 0.4586\n",
      "78/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.6725 - accuracy: 0.3690 - val_loss: 3.3940 - val_accuracy: 0.4578\n",
      "79/300\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 3.6253 - accuracy: 0.3764 - val_loss: 3.4269 - val_accuracy: 0.4470\n",
      "80/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.6225 - accuracy: 0.3736 - val_loss: 3.3506 - val_accuracy: 0.4646\n",
      "81/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.4851 - accuracy: 0.3892 - val_loss: 3.2817 - val_accuracy: 0.4786\n",
      "82/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.5134 - accuracy: 0.4000 - val_loss: 3.2836 - val_accuracy: 0.4868\n",
      "83/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.5330 - accuracy: 0.3892 - val_loss: 3.1912 - val_accuracy: 0.5032\n",
      "84/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.4308 - accuracy: 0.4144 - val_loss: 3.1069 - val_accuracy: 0.5166\n",
      "85/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.4255 - accuracy: 0.4128 - val_loss: 3.0988 - val_accuracy: 0.5118\n",
      "86/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.3229 - accuracy: 0.4288 - val_loss: 3.0005 - val_accuracy: 0.5290\n",
      "87/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 3.2930 - accuracy: 0.4366 - val_loss: 3.0024 - val_accuracy: 0.5310\n",
      "88/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.1925 - accuracy: 0.4526 - val_loss: 2.9745 - val_accuracy: 0.5504\n",
      "89/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 3.1956 - accuracy: 0.4598 - val_loss: 2.9503 - val_accuracy: 0.5616\n",
      "90/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 3.1495 - accuracy: 0.4696 - val_loss: 2.9135 - val_accuracy: 0.5590\n",
      "91/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 3.1303 - accuracy: 0.4646 - val_loss: 2.8207 - val_accuracy: 0.5738\n",
      "92/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 3.0353 - accuracy: 0.4810 - val_loss: 2.8283 - val_accuracy: 0.5768\n",
      "93/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 3.0062 - accuracy: 0.4880 - val_loss: 2.7604 - val_accuracy: 0.5832\n",
      "94/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.9696 - accuracy: 0.4948 - val_loss: 2.6471 - val_accuracy: 0.5980\n",
      "95/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.9144 - accuracy: 0.5114 - val_loss: 2.6240 - val_accuracy: 0.5998\n",
      "96/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.8130 - accuracy: 0.5318 - val_loss: 2.5803 - val_accuracy: 0.6196\n",
      "97/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.8321 - accuracy: 0.5246 - val_loss: 2.5944 - val_accuracy: 0.6220\n",
      "98/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7949 - accuracy: 0.5242 - val_loss: 2.5451 - val_accuracy: 0.6238\n",
      "99/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.6749 - accuracy: 0.5516 - val_loss: 2.4254 - val_accuracy: 0.6470\n",
      "100/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.6994 - accuracy: 0.5420 - val_loss: 2.3894 - val_accuracy: 0.6530\n",
      "101/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.6053 - accuracy: 0.5618 - val_loss: 2.3300 - val_accuracy: 0.6714\n",
      "102/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.6157 - accuracy: 0.5590 - val_loss: 2.3551 - val_accuracy: 0.6540\n",
      "103/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.5818 - accuracy: 0.5700 - val_loss: 2.2385 - val_accuracy: 0.6784\n",
      "104/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.4533 - accuracy: 0.5882 - val_loss: 2.2560 - val_accuracy: 0.6886\n",
      "105/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.4619 - accuracy: 0.5912 - val_loss: 2.1691 - val_accuracy: 0.6950\n",
      "106/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.4157 - accuracy: 0.6046 - val_loss: 2.2082 - val_accuracy: 0.6972\n",
      "107/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3658 - accuracy: 0.6142 - val_loss: 2.0858 - val_accuracy: 0.7072\n",
      "108/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3163 - accuracy: 0.6272 - val_loss: 2.0404 - val_accuracy: 0.7236\n",
      "109/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2927 - accuracy: 0.6250 - val_loss: 2.0611 - val_accuracy: 0.7250\n",
      "110/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2357 - accuracy: 0.6340 - val_loss: 1.9258 - val_accuracy: 0.7340\n",
      "111/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.1814 - accuracy: 0.6494 - val_loss: 1.9285 - val_accuracy: 0.7324\n",
      "112/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.1587 - accuracy: 0.6494 - val_loss: 1.9458 - val_accuracy: 0.7302\n",
      "113/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.1665 - accuracy: 0.6526 - val_loss: 1.8492 - val_accuracy: 0.7476\n",
      "114/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.1373 - accuracy: 0.6576 - val_loss: 1.8224 - val_accuracy: 0.7550\n",
      "115/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.0726 - accuracy: 0.6674 - val_loss: 1.8891 - val_accuracy: 0.7382\n",
      "116/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.9581 - accuracy: 0.6914 - val_loss: 1.7231 - val_accuracy: 0.7748\n",
      "117/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.9392 - accuracy: 0.6912 - val_loss: 1.6810 - val_accuracy: 0.7768\n",
      "118/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.9494 - accuracy: 0.6956 - val_loss: 1.6944 - val_accuracy: 0.7752\n",
      "119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step - loss: 1.8986 - accuracy: 0.7064 - val_loss: 1.7341 - val_accuracy: 0.7634\n",
      "120/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.9043 - accuracy: 0.7002 - val_loss: 1.5780 - val_accuracy: 0.7956\n",
      "121/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.8292 - accuracy: 0.7132 - val_loss: 1.5542 - val_accuracy: 0.7966\n",
      "122/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.7196 - accuracy: 0.7368 - val_loss: 1.6183 - val_accuracy: 0.7830\n",
      "123/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.8194 - accuracy: 0.7180 - val_loss: 1.4887 - val_accuracy: 0.8030\n",
      "124/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.7639 - accuracy: 0.7308 - val_loss: 1.4975 - val_accuracy: 0.7984\n",
      "125/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.6355 - accuracy: 0.7424 - val_loss: 1.5286 - val_accuracy: 0.8056\n",
      "126/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.6499 - accuracy: 0.7464 - val_loss: 1.4781 - val_accuracy: 0.8036\n",
      "127/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.5977 - accuracy: 0.7530 - val_loss: 1.3621 - val_accuracy: 0.8228\n",
      "128/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.5823 - accuracy: 0.7650 - val_loss: 1.3348 - val_accuracy: 0.8294\n",
      "129/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.5391 - accuracy: 0.7650 - val_loss: 1.3660 - val_accuracy: 0.8202\n",
      "130/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.4999 - accuracy: 0.7734 - val_loss: 1.2372 - val_accuracy: 0.8432\n",
      "131/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.5245 - accuracy: 0.7708 - val_loss: 1.2279 - val_accuracy: 0.8386\n",
      "132/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.4933 - accuracy: 0.7750 - val_loss: 1.1732 - val_accuracy: 0.8542\n",
      "133/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.4657 - accuracy: 0.7784 - val_loss: 1.2039 - val_accuracy: 0.8498\n",
      "134/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.4052 - accuracy: 0.7870 - val_loss: 1.1889 - val_accuracy: 0.8542\n",
      "135/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.3509 - accuracy: 0.7950 - val_loss: 1.1856 - val_accuracy: 0.8552\n",
      "136/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.4031 - accuracy: 0.7902 - val_loss: 1.1489 - val_accuracy: 0.8564\n",
      "137/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.3757 - accuracy: 0.7934 - val_loss: 1.1141 - val_accuracy: 0.8648\n",
      "138/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.4224 - accuracy: 0.7934 - val_loss: 1.1265 - val_accuracy: 0.8604\n",
      "139/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.3302 - accuracy: 0.8030 - val_loss: 1.0405 - val_accuracy: 0.8744\n",
      "140/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.3042 - accuracy: 0.8096 - val_loss: 1.0341 - val_accuracy: 0.8800\n",
      "141/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.2430 - accuracy: 0.8156 - val_loss: 1.0415 - val_accuracy: 0.8678\n",
      "142/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.2480 - accuracy: 0.8138 - val_loss: 0.9930 - val_accuracy: 0.8802\n",
      "143/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1926 - accuracy: 0.8262 - val_loss: 0.9918 - val_accuracy: 0.8738\n",
      "144/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1910 - accuracy: 0.8294 - val_loss: 0.9623 - val_accuracy: 0.8844\n",
      "145/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.1521 - accuracy: 0.8360 - val_loss: 0.9279 - val_accuracy: 0.8794\n",
      "146/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1143 - accuracy: 0.8408 - val_loss: 0.8919 - val_accuracy: 0.8944\n",
      "147/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.1186 - accuracy: 0.8384 - val_loss: 0.9097 - val_accuracy: 0.8848\n",
      "148/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.1073 - accuracy: 0.8456 - val_loss: 0.9266 - val_accuracy: 0.8856\n",
      "149/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1149 - accuracy: 0.8386 - val_loss: 0.9002 - val_accuracy: 0.8940\n",
      "150/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.1647 - accuracy: 0.8362 - val_loss: 0.8930 - val_accuracy: 0.8912\n",
      "151/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0037 - accuracy: 0.8596 - val_loss: 0.8458 - val_accuracy: 0.8982\n",
      "152/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0690 - accuracy: 0.8488 - val_loss: 0.8280 - val_accuracy: 0.8990\n",
      "153/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9792 - accuracy: 0.8668 - val_loss: 0.7732 - val_accuracy: 0.9080\n",
      "154/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9705 - accuracy: 0.8670 - val_loss: 0.7828 - val_accuracy: 0.9032\n",
      "155/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0386 - accuracy: 0.8534 - val_loss: 0.7703 - val_accuracy: 0.9068\n",
      "156/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9605 - accuracy: 0.8642 - val_loss: 0.7292 - val_accuracy: 0.9092\n",
      "157/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.9595 - accuracy: 0.8602 - val_loss: 0.7520 - val_accuracy: 0.9062\n",
      "158/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.9116 - accuracy: 0.8712 - val_loss: 0.7109 - val_accuracy: 0.9174\n",
      "159/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.8887 - accuracy: 0.8788 - val_loss: 0.7278 - val_accuracy: 0.9122\n",
      "160/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9097 - accuracy: 0.8710 - val_loss: 0.6826 - val_accuracy: 0.9196\n",
      "161/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8853 - accuracy: 0.8784 - val_loss: 0.7242 - val_accuracy: 0.9164\n",
      "162/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8704 - accuracy: 0.8784 - val_loss: 0.6518 - val_accuracy: 0.9216\n",
      "163/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8381 - accuracy: 0.8852 - val_loss: 0.6889 - val_accuracy: 0.9134\n",
      "164/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8512 - accuracy: 0.8792 - val_loss: 0.6819 - val_accuracy: 0.9206\n",
      "165/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8168 - accuracy: 0.8912 - val_loss: 0.6356 - val_accuracy: 0.9192\n",
      "166/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8776 - accuracy: 0.8874 - val_loss: 0.6600 - val_accuracy: 0.9218\n",
      "167/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8001 - accuracy: 0.8882 - val_loss: 0.6210 - val_accuracy: 0.9280\n",
      "168/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8200 - accuracy: 0.8870 - val_loss: 0.7071 - val_accuracy: 0.9076\n",
      "169/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8239 - accuracy: 0.8870 - val_loss: 0.6239 - val_accuracy: 0.9256\n",
      "170/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.7479 - accuracy: 0.9016 - val_loss: 0.6440 - val_accuracy: 0.9232\n",
      "171/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8369 - accuracy: 0.8844 - val_loss: 0.5727 - val_accuracy: 0.9286\n",
      "172/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.7529 - accuracy: 0.8960 - val_loss: 0.6129 - val_accuracy: 0.9240\n",
      "173/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.7799 - accuracy: 0.8928 - val_loss: 0.6009 - val_accuracy: 0.9248\n",
      "174/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.7330 - accuracy: 0.9026 - val_loss: 0.6208 - val_accuracy: 0.9196\n",
      "175/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.7987 - accuracy: 0.8934 - val_loss: 0.5340 - val_accuracy: 0.9344\n",
      "176/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6843 - accuracy: 0.9140 - val_loss: 0.5307 - val_accuracy: 0.9342\n",
      "177/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6728 - accuracy: 0.9102 - val_loss: 0.5404 - val_accuracy: 0.9354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6857 - accuracy: 0.9124 - val_loss: 0.5642 - val_accuracy: 0.9290\n",
      "179/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.7172 - accuracy: 0.9026 - val_loss: 0.5431 - val_accuracy: 0.9372\n",
      "180/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6889 - accuracy: 0.9076 - val_loss: 0.5423 - val_accuracy: 0.9294\n",
      "181/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6679 - accuracy: 0.9100 - val_loss: 0.5244 - val_accuracy: 0.9396\n",
      "182/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6703 - accuracy: 0.9084 - val_loss: 0.5207 - val_accuracy: 0.9316\n",
      "183/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6582 - accuracy: 0.9090 - val_loss: 0.5481 - val_accuracy: 0.9346\n",
      "184/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6813 - accuracy: 0.9086 - val_loss: 0.4980 - val_accuracy: 0.9336\n",
      "185/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6989 - accuracy: 0.9042 - val_loss: 0.5440 - val_accuracy: 0.9352\n",
      "186/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6053 - accuracy: 0.9154 - val_loss: 0.4777 - val_accuracy: 0.9394\n",
      "187/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5989 - accuracy: 0.9206 - val_loss: 0.4622 - val_accuracy: 0.9476\n",
      "188/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6552 - accuracy: 0.9146 - val_loss: 0.5849 - val_accuracy: 0.9382\n",
      "189/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6807 - accuracy: 0.9126 - val_loss: 0.4514 - val_accuracy: 0.9508\n",
      "190/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5840 - accuracy: 0.9242 - val_loss: 0.4585 - val_accuracy: 0.9522\n",
      "191/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5817 - accuracy: 0.9250 - val_loss: 0.4212 - val_accuracy: 0.9496\n",
      "192/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6181 - accuracy: 0.9172 - val_loss: 0.4553 - val_accuracy: 0.9436\n",
      "193/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5860 - accuracy: 0.9178 - val_loss: 0.5003 - val_accuracy: 0.9450\n",
      "194/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5574 - accuracy: 0.9248 - val_loss: 0.4869 - val_accuracy: 0.9392\n",
      "195/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5925 - accuracy: 0.9222 - val_loss: 0.4371 - val_accuracy: 0.9452\n",
      "196/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6486 - accuracy: 0.9200 - val_loss: 0.4844 - val_accuracy: 0.9404\n",
      "197/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6353 - accuracy: 0.9148 - val_loss: 0.4938 - val_accuracy: 0.9352\n",
      "198/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5967 - accuracy: 0.9222 - val_loss: 0.4432 - val_accuracy: 0.9442\n",
      "199/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5150 - accuracy: 0.9296 - val_loss: 0.4527 - val_accuracy: 0.9418\n",
      "200/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5864 - accuracy: 0.9256 - val_loss: 0.4077 - val_accuracy: 0.9456\n",
      "201/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5785 - accuracy: 0.9228 - val_loss: 0.4269 - val_accuracy: 0.9460\n",
      "202/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5262 - accuracy: 0.9322 - val_loss: 0.4400 - val_accuracy: 0.9444\n",
      "203/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5098 - accuracy: 0.9304 - val_loss: 0.4113 - val_accuracy: 0.9544\n",
      "204/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5465 - accuracy: 0.9288 - val_loss: 0.4110 - val_accuracy: 0.9494\n",
      "205/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.4899 - accuracy: 0.9360 - val_loss: 0.3554 - val_accuracy: 0.9568\n",
      "206/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5354 - accuracy: 0.9334 - val_loss: 0.4497 - val_accuracy: 0.9436\n",
      "207/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5071 - accuracy: 0.9348 - val_loss: 0.3732 - val_accuracy: 0.9508\n",
      "208/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5571 - accuracy: 0.9288 - val_loss: 0.4044 - val_accuracy: 0.9534\n",
      "209/300\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5415 - accuracy: 0.9342 - val_loss: 0.4051 - val_accuracy: 0.9446\n",
      "210/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4621 - accuracy: 0.9400 - val_loss: 0.3486 - val_accuracy: 0.9566\n",
      "211/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4777 - accuracy: 0.9402 - val_loss: 0.3991 - val_accuracy: 0.9470\n",
      "212/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4709 - accuracy: 0.9344 - val_loss: 0.3692 - val_accuracy: 0.9548\n",
      "213/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.5109 - accuracy: 0.9338 - val_loss: 0.3963 - val_accuracy: 0.9494\n",
      "214/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5060 - accuracy: 0.9338 - val_loss: 0.4411 - val_accuracy: 0.9462\n",
      "215/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.6113 - accuracy: 0.9222 - val_loss: 0.3912 - val_accuracy: 0.9532\n",
      "216/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4460 - accuracy: 0.9400 - val_loss: 0.3356 - val_accuracy: 0.9580\n",
      "217/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4329 - accuracy: 0.9416 - val_loss: 0.3359 - val_accuracy: 0.9534\n",
      "218/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5327 - accuracy: 0.9272 - val_loss: 0.3691 - val_accuracy: 0.9484\n",
      "219/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4527 - accuracy: 0.9434 - val_loss: 0.3208 - val_accuracy: 0.9614\n",
      "220/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4993 - accuracy: 0.9340 - val_loss: 0.3145 - val_accuracy: 0.9594\n",
      "221/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.9400 - val_loss: 0.3735 - val_accuracy: 0.9514\n",
      "222/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4854 - accuracy: 0.9356 - val_loss: 0.3109 - val_accuracy: 0.9624\n",
      "223/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4905 - accuracy: 0.9334 - val_loss: 0.3609 - val_accuracy: 0.9546\n",
      "224/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.9394 - val_loss: 0.3235 - val_accuracy: 0.9608\n",
      "225/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.5331 - accuracy: 0.9336 - val_loss: 0.3335 - val_accuracy: 0.9592\n",
      "226/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4869 - accuracy: 0.9338 - val_loss: 0.4649 - val_accuracy: 0.9354\n",
      "227/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.5208 - accuracy: 0.9290 - val_loss: 0.2989 - val_accuracy: 0.9624\n",
      "228/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4486 - accuracy: 0.9384 - val_loss: 0.3311 - val_accuracy: 0.9572\n",
      "229/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4408 - accuracy: 0.9404 - val_loss: 0.2919 - val_accuracy: 0.9616\n",
      "230/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4009 - accuracy: 0.9444 - val_loss: 0.3098 - val_accuracy: 0.9604\n",
      "231/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3965 - accuracy: 0.9470 - val_loss: 0.3424 - val_accuracy: 0.9546\n",
      "232/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.9474 - val_loss: 0.2884 - val_accuracy: 0.9640\n",
      "233/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4491 - accuracy: 0.9426 - val_loss: 0.2981 - val_accuracy: 0.9596\n",
      "234/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4391 - accuracy: 0.9396 - val_loss: 0.2759 - val_accuracy: 0.9614\n",
      "235/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3580 - accuracy: 0.9518 - val_loss: 0.3096 - val_accuracy: 0.9584\n",
      "236/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4104 - accuracy: 0.9480 - val_loss: 0.3567 - val_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.5058 - accuracy: 0.9346 - val_loss: 0.3590 - val_accuracy: 0.9538\n",
      "238/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5044 - accuracy: 0.9306 - val_loss: 0.2993 - val_accuracy: 0.9600\n",
      "239/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.9382 - val_loss: 0.3191 - val_accuracy: 0.9570\n",
      "240/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4774 - accuracy: 0.9426 - val_loss: 0.3969 - val_accuracy: 0.9496\n",
      "241/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3663 - accuracy: 0.9490 - val_loss: 0.3375 - val_accuracy: 0.9616\n",
      "242/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3866 - accuracy: 0.9482 - val_loss: 0.3168 - val_accuracy: 0.9582\n",
      "243/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3905 - accuracy: 0.9506 - val_loss: 0.3135 - val_accuracy: 0.9582\n",
      "244/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.4662 - accuracy: 0.9334 - val_loss: 0.2835 - val_accuracy: 0.9650\n",
      "245/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4883 - accuracy: 0.9346 - val_loss: 0.3410 - val_accuracy: 0.9594\n",
      "246/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4145 - accuracy: 0.9428 - val_loss: 0.3143 - val_accuracy: 0.9608\n",
      "247/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3464 - accuracy: 0.9522 - val_loss: 0.3098 - val_accuracy: 0.9582\n",
      "248/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4036 - accuracy: 0.9488 - val_loss: 0.3011 - val_accuracy: 0.9628\n",
      "249/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4154 - accuracy: 0.9444 - val_loss: 0.3105 - val_accuracy: 0.9612\n",
      "250/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3787 - accuracy: 0.9528 - val_loss: 0.2710 - val_accuracy: 0.9704\n",
      "251/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4473 - accuracy: 0.9432 - val_loss: 0.2673 - val_accuracy: 0.9662\n",
      "252/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4104 - accuracy: 0.9492 - val_loss: 0.3386 - val_accuracy: 0.9536\n",
      "253/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.4543 - accuracy: 0.9412 - val_loss: 0.3157 - val_accuracy: 0.9626\n",
      "254/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3541 - accuracy: 0.9502 - val_loss: 0.2242 - val_accuracy: 0.9712\n",
      "255/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3933 - accuracy: 0.9474 - val_loss: 0.2774 - val_accuracy: 0.9648\n",
      "256/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4410 - accuracy: 0.9408 - val_loss: 0.2226 - val_accuracy: 0.9736\n",
      "257/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.4030 - accuracy: 0.9476 - val_loss: 0.2606 - val_accuracy: 0.9680\n",
      "258/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3489 - accuracy: 0.9530 - val_loss: 0.2499 - val_accuracy: 0.9696\n",
      "259/300\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3665 - accuracy: 0.9518 - val_loss: 0.2309 - val_accuracy: 0.9684\n",
      "260/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3599 - accuracy: 0.9502 - val_loss: 0.2908 - val_accuracy: 0.9648\n",
      "261/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4169 - accuracy: 0.9490 - val_loss: 0.2989 - val_accuracy: 0.9568\n",
      "262/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3768 - accuracy: 0.9480 - val_loss: 0.3583 - val_accuracy: 0.9512\n",
      "263/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3812 - accuracy: 0.9458 - val_loss: 0.2926 - val_accuracy: 0.9610\n",
      "264/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.4055 - accuracy: 0.9458 - val_loss: 0.2207 - val_accuracy: 0.9734\n",
      "265/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3533 - accuracy: 0.9494 - val_loss: 0.2742 - val_accuracy: 0.9642\n",
      "266/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3842 - accuracy: 0.9488 - val_loss: 0.2521 - val_accuracy: 0.9688\n",
      "267/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3753 - accuracy: 0.9496 - val_loss: 0.2550 - val_accuracy: 0.9650\n",
      "268/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3617 - accuracy: 0.9516 - val_loss: 0.2598 - val_accuracy: 0.9644\n",
      "269/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.4380 - accuracy: 0.9446 - val_loss: 0.2741 - val_accuracy: 0.9660\n",
      "270/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4729 - accuracy: 0.9386 - val_loss: 0.2622 - val_accuracy: 0.9636\n",
      "271/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.4549 - accuracy: 0.9416 - val_loss: 0.2536 - val_accuracy: 0.9652\n",
      "272/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4601 - accuracy: 0.9428 - val_loss: 0.2892 - val_accuracy: 0.9608\n",
      "273/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.3785 - accuracy: 0.9504 - val_loss: 0.2589 - val_accuracy: 0.9712\n",
      "274/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3957 - accuracy: 0.9504 - val_loss: 0.2281 - val_accuracy: 0.9698\n",
      "275/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3616 - accuracy: 0.9542 - val_loss: 0.2624 - val_accuracy: 0.9660\n",
      "276/300\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.3797 - accuracy: 0.9518 - val_loss: 0.2696 - val_accuracy: 0.9638\n",
      "277/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3780 - accuracy: 0.9508 - val_loss: 0.2692 - val_accuracy: 0.9652\n",
      "278/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3190 - accuracy: 0.9560 - val_loss: 0.2785 - val_accuracy: 0.9666\n",
      "279/300\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.3343 - accuracy: 0.9540 - val_loss: 0.3411 - val_accuracy: 0.9640\n",
      "280/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3394 - accuracy: 0.9554 - val_loss: 0.2877 - val_accuracy: 0.9622\n",
      "281/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2800 - accuracy: 0.9632 - val_loss: 0.2768 - val_accuracy: 0.9654\n",
      "282/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3887 - accuracy: 0.9454 - val_loss: 0.2704 - val_accuracy: 0.9702\n",
      "283/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4134 - accuracy: 0.9470 - val_loss: 0.2756 - val_accuracy: 0.9642\n",
      "284/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.3604 - accuracy: 0.9552 - val_loss: 0.2924 - val_accuracy: 0.9606\n",
      "285/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.4063 - accuracy: 0.9484 - val_loss: 0.2491 - val_accuracy: 0.9652\n",
      "286/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3506 - accuracy: 0.9476 - val_loss: 0.2970 - val_accuracy: 0.9678\n",
      "287/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3862 - accuracy: 0.9528 - val_loss: 0.3147 - val_accuracy: 0.9598\n",
      "288/300\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.3273 - accuracy: 0.9506 - val_loss: 0.3084 - val_accuracy: 0.9672\n",
      "289/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3565 - accuracy: 0.9550 - val_loss: 0.2299 - val_accuracy: 0.9668\n",
      "290/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3896 - accuracy: 0.9528 - val_loss: 0.1901 - val_accuracy: 0.9728\n",
      "291/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3602 - accuracy: 0.9528 - val_loss: 0.2461 - val_accuracy: 0.9656\n",
      "292/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3487 - accuracy: 0.9542 - val_loss: 0.2697 - val_accuracy: 0.9674\n",
      "293/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3490 - accuracy: 0.9510 - val_loss: 0.1818 - val_accuracy: 0.9758\n",
      "294/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4055 - accuracy: 0.9496 - val_loss: 0.2974 - val_accuracy: 0.9614\n",
      "295/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3600 - accuracy: 0.9532 - val_loss: 0.2546 - val_accuracy: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3782 - accuracy: 0.9542 - val_loss: 0.2531 - val_accuracy: 0.9724\n",
      "297/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3374 - accuracy: 0.9570 - val_loss: 0.2185 - val_accuracy: 0.9682\n",
      "298/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3363 - accuracy: 0.9590 - val_loss: 0.2096 - val_accuracy: 0.9714\n",
      "299/300\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3088 - accuracy: 0.9602 - val_loss: 0.2405 - val_accuracy: 0.9726\n",
      "300/300\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3797 - accuracy: 0.9540 - val_loss: 0.2500 - val_accuracy: 0.9682\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 0.2380 - accuracy: 0.9708\n",
      "Train set: Loss=0.2380 ; Accuracy=97.1%\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 33.8262 - accuracy: 0.0213\n",
      "Test set: Loss=33.8262 ; Accuracy=2.1%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m eg\u001b[38;5;241m.\u001b[39mtest(dg\u001b[38;5;241m.\u001b[39muser_test)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest set: Loss=\u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m ; Accuracy=\u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (test_loss, test_accuracy \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m \u001b[43meg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membeddings.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 68\u001b[0m, in \u001b[0;36mEmbeddingsGenerator.save_embeddings\u001b[1;34m(self, file_name)\u001b[0m\n\u001b[0;32m     66\u001b[0m inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39minput  \u001b[38;5;66;03m# input placeholder\u001b[39;00m\n\u001b[0;32m     67\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [layer\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mlayers]  \u001b[38;5;66;03m# all layer outputs\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m functor \u001b[38;5;241m=\u001b[39m \u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# evaluation function\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# append embeddings to vectors\u001b[39;00m\n\u001b[0;32m     71\u001b[0m vectors \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\backend.py:4655\u001b[0m, in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[0;32m   4649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`updates` argument is not supported during \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4651\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager execution. You passed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (updates,)\n\u001b[0;32m   4652\u001b[0m     )\n\u001b[0;32m   4653\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m-> 4655\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4657\u001b[0m wrap_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4659\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(model_inputs):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\functional.py:159\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m--> 159\u001b[0m         [\n\u001b[0;32m    160\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    162\u001b[0m         ]\n\u001b[0;32m    163\u001b[0m     ):\n\u001b[0;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    165\u001b[0m             inputs, outputs\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\functional.py:160\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    159\u001b[0m         [\n\u001b[1;32m--> 160\u001b[0m             \u001b[43mfunctional_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_input_keras_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    162\u001b[0m         ]\n\u001b[0;32m    163\u001b[0m     ):\n\u001b[0;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    165\u001b[0m             inputs, outputs\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\functional_utils.py:48\u001b[0m, in \u001b[0;36mis_input_keras_tensor\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check if tensor is directly generated from `tf.keras.Input`.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mThis check is useful when constructing the functional model, since we will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m  ValueError: if the tensor is not a KerasTensor instance.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node_module\u001b[38;5;241m.\u001b[39mis_keras_tensor(tensor):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[38;5;241m.\u001b[39mformat(tensor))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mis_input\n",
      "\u001b[1;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: 0"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    eg = EmbeddingsGenerator(dg.user_train, pd.read_csv('ml-100k/u.data', sep='\\t', names=['userId', 'itemId', 'rating', 'timestamp']))\n",
    "    eg.train(nb_epochs=300)\n",
    "    train_loss, train_accuracy = eg.test(dg.user_train)\n",
    "    print('Train set: Loss=%.4f ; Accuracy=%.1f%%' % (train_loss, train_accuracy * 100))\n",
    "    test_loss, test_accuracy = eg.test(dg.user_test)\n",
    "    print('Test set: Loss=%.4f ; Accuracy=%.1f%%' % (test_loss, test_accuracy * 100))\n",
    "    eg.save_embeddings('embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cbad82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embeddings(read_embeddings('embeddings.csv'))\n",
    "\n",
    "state_space_size = embeddings.size() * history_length\n",
    "action_space_size = embeddings.size() * ra_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09df572",
   "metadata": {},
   "source": [
    "**GROUPED COSINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b14499b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100 Reward=543 Q_value=0 Time=3s No replay\n",
      "Episode 2/100 Reward=543 Q_value=399 Time=55s Loss=344.4909\n",
      "Episode 3/100 Reward=543 Q_value=573 Time=71s Loss=9.0435\n",
      "Episode 4/100 Reward=544 Q_value=559 Time=71s Loss=5.1186\n",
      "Episode 5/100 Reward=544 Q_value=558 Time=71s Loss=5.1347\n",
      "Episode 6/100 Reward=543 Q_value=554 Time=72s Loss=2.6288\n",
      "Episode 7/100 Reward=544 Q_value=558 Time=72s Loss=2.6439\n",
      "Episode 8/100 Reward=543 Q_value=545 Time=71s Loss=1.1152\n",
      "Episode 9/100 Reward=543 Q_value=546 Time=74s Loss=0.6272\n",
      "Episode 10/100 Reward=543 Q_value=541 Time=74s Loss=0.3239\n",
      "Episode 11/100 Reward=544 Q_value=538 Time=71s Loss=0.0970\n",
      "Episode 12/100 Reward=544 Q_value=541 Time=72s Loss=0.1753\n",
      "Episode 13/100 Reward=544 Q_value=541 Time=71s Loss=0.1413\n",
      "Episode 14/100 Reward=544 Q_value=542 Time=72s Loss=0.1117\n",
      "Episode 15/100 Reward=544 Q_value=542 Time=70s Loss=0.1042\n",
      "Episode 16/100 Reward=544 Q_value=541 Time=70s Loss=0.1342\n",
      "Episode 17/100 Reward=544 Q_value=539 Time=72s Loss=0.1051\n",
      "Episode 18/100 Reward=544 Q_value=539 Time=71s Loss=0.1177\n",
      "Episode 19/100 Reward=544 Q_value=539 Time=72s Loss=0.2973\n",
      "Episode 20/100 Reward=544 Q_value=541 Time=73s Loss=0.8433\n",
      "Episode 21/100 Reward=544 Q_value=539 Time=71s Loss=0.3724\n",
      "Episode 22/100 Reward=544 Q_value=538 Time=71s Loss=0.2022\n",
      "Episode 23/100 Reward=544 Q_value=539 Time=73s Loss=0.2206\n",
      "Episode 24/100 Reward=544 Q_value=541 Time=74s Loss=2.4288\n",
      "Episode 25/100 Reward=544 Q_value=540 Time=72s Loss=0.3722\n",
      "Episode 26/100 Reward=544 Q_value=540 Time=71s Loss=0.1346\n",
      "Episode 27/100 Reward=544 Q_value=539 Time=71s Loss=0.1038\n",
      "Episode 28/100 Reward=544 Q_value=539 Time=71s Loss=0.0673\n",
      "Episode 29/100 Reward=544 Q_value=540 Time=72s Loss=4.3379\n",
      "Episode 30/100 Reward=544 Q_value=543 Time=74s Loss=1.6125\n",
      "Episode 31/100 Reward=544 Q_value=540 Time=71s Loss=0.0803\n",
      "Episode 32/100 Reward=544 Q_value=539 Time=72s Loss=0.0488\n",
      "Episode 33/100 Reward=544 Q_value=538 Time=73s Loss=0.1103\n",
      "Episode 34/100 Reward=544 Q_value=538 Time=70s Loss=0.0963\n",
      "Episode 35/100 Reward=544 Q_value=538 Time=72s Loss=0.2577\n",
      "Episode 36/100 Reward=544 Q_value=540 Time=72s Loss=1.3948\n",
      "Episode 37/100 Reward=544 Q_value=539 Time=73s Loss=0.3058\n",
      "Episode 38/100 Reward=544 Q_value=538 Time=73s Loss=0.8100\n",
      "Episode 39/100 Reward=544 Q_value=539 Time=75s Loss=1.3496\n",
      "Episode 40/100 Reward=544 Q_value=539 Time=73s Loss=0.1889\n",
      "Episode 41/100 Reward=544 Q_value=538 Time=71s Loss=0.8948\n",
      "Episode 42/100 Reward=544 Q_value=540 Time=70s Loss=0.7601\n",
      "Episode 43/100 Reward=544 Q_value=539 Time=69s Loss=1.2481\n",
      "Episode 44/100 Reward=544 Q_value=540 Time=70s Loss=6.3219\n",
      "Episode 45/100 Reward=544 Q_value=541 Time=70s Loss=1.1618\n",
      "Episode 46/100 Reward=544 Q_value=539 Time=72s Loss=0.0802\n",
      "Episode 47/100 Reward=544 Q_value=538 Time=70s Loss=0.0247\n",
      "Episode 48/100 Reward=544 Q_value=538 Time=70s Loss=0.0984\n",
      "Episode 49/100 Reward=544 Q_value=539 Time=70s Loss=0.0879\n",
      "Episode 50/100 Reward=544 Q_value=538 Time=71s Loss=0.0406\n",
      "Episode 51/100 Reward=544 Q_value=539 Time=70s Loss=0.1021\n",
      "Episode 52/100 Reward=544 Q_value=538 Time=71s Loss=0.3615\n",
      "Episode 53/100 Reward=544 Q_value=538 Time=70s Loss=0.8063\n",
      "Episode 54/100 Reward=544 Q_value=539 Time=71s Loss=0.5328\n",
      "Episode 55/100 Reward=544 Q_value=540 Time=71s Loss=2.1173\n",
      "Episode 56/100 Reward=544 Q_value=539 Time=71s Loss=0.2574\n",
      "Episode 57/100 Reward=544 Q_value=538 Time=70s Loss=0.0566\n",
      "Episode 58/100 Reward=544 Q_value=539 Time=70s Loss=1.5398\n",
      "Episode 59/100 Reward=544 Q_value=540 Time=70s Loss=1.7107\n",
      "Episode 60/100 Reward=544 Q_value=540 Time=71s Loss=0.4400\n",
      "Episode 61/100 Reward=544 Q_value=538 Time=71s Loss=0.1482\n",
      "Episode 62/100 Reward=544 Q_value=537 Time=72s Loss=0.1060\n",
      "Episode 63/100 Reward=544 Q_value=536 Time=71s Loss=0.0712\n",
      "Episode 64/100 Reward=544 Q_value=538 Time=71s Loss=1.4831\n",
      "Episode 65/100 Reward=544 Q_value=539 Time=70s Loss=0.9878\n",
      "Episode 66/100 Reward=544 Q_value=539 Time=70s Loss=1.2755\n",
      "Episode 67/100 Reward=544 Q_value=536 Time=70s Loss=0.3178\n",
      "Episode 68/100 Reward=544 Q_value=535 Time=70s Loss=0.2904\n",
      "Episode 69/100 Reward=544 Q_value=537 Time=72s Loss=1.6686\n",
      "Episode 70/100 Reward=544 Q_value=537 Time=71s Loss=1.7300\n",
      "Episode 71/100 Reward=544 Q_value=538 Time=71s Loss=0.0880\n",
      "Episode 72/100 Reward=544 Q_value=536 Time=71s Loss=0.1286\n",
      "Episode 73/100 Reward=544 Q_value=536 Time=71s Loss=0.1783\n",
      "Episode 74/100 Reward=544 Q_value=536 Time=70s Loss=0.1864\n",
      "Episode 75/100 Reward=544 Q_value=535 Time=72s Loss=1.3282\n",
      "Episode 76/100 Reward=544 Q_value=537 Time=71s Loss=0.7683\n",
      "Episode 77/100 Reward=544 Q_value=536 Time=70s Loss=0.0562\n",
      "Episode 78/100 Reward=544 Q_value=536 Time=71s Loss=0.2993\n",
      "Episode 79/100 Reward=544 Q_value=536 Time=70s Loss=0.5005\n",
      "Episode 80/100 Reward=544 Q_value=537 Time=71s Loss=1.4681\n",
      "Episode 81/100 Reward=544 Q_value=537 Time=70s Loss=0.7256\n",
      "Episode 82/100 Reward=544 Q_value=535 Time=71s Loss=0.1560\n",
      "Episode 83/100 Reward=544 Q_value=536 Time=72s Loss=0.5249\n",
      "Episode 84/100 Reward=544 Q_value=537 Time=72s Loss=1.2457\n",
      "Episode 85/100 Reward=544 Q_value=537 Time=71s Loss=0.7511\n",
      "Episode 86/100 Reward=544 Q_value=536 Time=72s Loss=0.1435\n",
      "Episode 87/100 Reward=544 Q_value=536 Time=73s Loss=0.3796\n",
      "Episode 88/100 Reward=544 Q_value=536 Time=73s Loss=0.2026\n",
      "Episode 89/100 Reward=544 Q_value=536 Time=73s Loss=1.3390\n",
      "Episode 90/100 Reward=544 Q_value=538 Time=73s Loss=2.1814\n",
      "Episode 91/100 Reward=544 Q_value=536 Time=74s Loss=0.1259\n",
      "Episode 92/100 Reward=544 Q_value=535 Time=72s Loss=0.2978\n",
      "Episode 93/100 Reward=544 Q_value=535 Time=72s Loss=0.0580\n",
      "Episode 94/100 Reward=544 Q_value=535 Time=73s Loss=0.0715\n",
      "Episode 95/100 Reward=544 Q_value=536 Time=71s Loss=0.2352\n",
      "Episode 96/100 Reward=544 Q_value=536 Time=72s Loss=0.2260\n",
      "Episode 97/100 Reward=544 Q_value=537 Time=72s Loss=1.3967\n",
      "Episode 98/100 Reward=544 Q_value=537 Time=72s Loss=0.4417\n",
      "Episode 99/100 Reward=544 Q_value=536 Time=72s Loss=0.2241\n",
      "Episode 100/100 Reward=544 Q_value=535 Time=72s Loss=0.1318\n"
     ]
    }
   ],
   "source": [
    "nb_episodes = 100\n",
    "\n",
    "environment = Environment(data, embeddings, alpha, gamma, fixed_length)\n",
    "\n",
    "tf.reset_default_graph() \n",
    "sess = tf.Session()\n",
    "actor = Actor(sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embeddings.size(), tau, actor_lr, net_name='actor_td3')\n",
    "critic1 = Critic(sess, state_space_size, action_space_size, history_length, embeddings.size(), tau, critic_lr,net_name='critic1')\n",
    "critic2 = Critic(sess, state_space_size, action_space_size, history_length, embeddings.size(), tau, critic_lr,net_name='critic2')\n",
    "\n",
    "q_values, time = train_td3(sess, environment, actor, critic1, critic2, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3247c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_embeddings = {}\n",
    "for i, item in enumerate(embeddings.get_embedding_vector()):\n",
    "    str_item = str(item)\n",
    "    assert(str_item not in dict_embeddings)\n",
    "    dict_embeddings[str_item] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8697da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_items(state, actor, ra_length, embeddings, dict_embeddings, target=False):\n",
    "    return [dict_embeddings[str(action)]\n",
    "        for action in actor.get_recommendation_list(ra_length, np.array(state).reshape(1, -1), embeddings, target).reshape(ra_length, embeddings.size())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d204cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_rounds = 100\n",
    "\n",
    "def test_actor(actor, test_df, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=1):\n",
    "    ratings = []\n",
    "    unknown = 0\n",
    "    random_seen = []\n",
    "    rec = []\n",
    "    for _ in range(nb_rounds):\n",
    "        for i in range(len(test_df)):\n",
    "            history_sample = list(test_df[i].sample(history_length)['itemId'])\n",
    "            recommendation = state_to_items(embeddings.embed(history_sample), actor, ra_length, embeddings, dict_embeddings, target)\n",
    "            rec_list = []\n",
    "            for item in recommendation:\n",
    "                l = list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])\n",
    "                assert(len(l) < 2)\n",
    "                if len(l) == 0:\n",
    "                    unknown += 1\n",
    "                else:\n",
    "                    ratings.append(l[0])\n",
    "                    rec_list.append(l[0])\n",
    "            if len(rec_list) >= 2:\n",
    "                rec.append(rec_list)\n",
    "        for item in history_sample:\n",
    "            random_seen.append(list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])[0])\n",
    "\n",
    "    return ratings, unknown, random_seen, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5f9dd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.1% unknown\n"
     ]
    }
   ],
   "source": [
    "ratings_grouped_cosine, unknown_grouped_cosine, random_seen, rec_list = test_actor(actor, dg.test, embeddings, dict_embeddings, ra_length, history_length, target=True, nb_rounds=100)\n",
    "print('%0.1f%% unknown' % (100 * unknown_grouped_cosine / (len(ratings_grouped_cosine) + unknown_grouped_cosine)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16f02e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def ndcg(rec_list):\n",
    "    total = 0\n",
    "    for i in range(len(rec_list)):\n",
    "        ideal = rec_list[i].copy()\n",
    "        ideal.sort(reverse=True)\n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        for j in range(len(rec_list[i])):\n",
    "            try:\n",
    "                dcg += rec_list[i][j]*0.2/math.log(j+2)\n",
    "                idcg += ideal[j]*0.2/math.log(j+2)\n",
    "            except ZeroDivisionError:\n",
    "                break\n",
    "        try:\n",
    "            total += dcg/idcg\n",
    "        except ZeroDivisionError:\n",
    "            print(\"\")\n",
    "    try:\n",
    "        print(total/len(rec_list))\n",
    "    except ZeroDivisionError:\n",
    "        print(\"\")\n",
    "ndcg(rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bcca8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def hr(rec_list):\n",
    "    total_1 = 0\n",
    "    for i in range(len(rec_list)):\n",
    "        for j in range(len(rec_list[i])):\n",
    "            if rec_list[i][j] == 5:\n",
    "                total_1 += 1\n",
    "                break\n",
    "    print(total_1/len(rec_list))\n",
    "    \n",
    "hr(rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c4ad9a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5945652173913072\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def mmr(rec_list)\n",
    "    total_2 = 0\n",
    "    for i in range(len(rec_list)):\n",
    "        t = 0\n",
    "        for j in range(len(rec_list[i])):\n",
    "            t += rec_list[i][j]*0.2/(j+1)\n",
    "\n",
    "        total_2 += t/len(rec_list[i])\n",
    "\n",
    "    print(total_2/len(rec_list))\n",
    "    \n",
    "mmr(rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "94cc6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ratings_grouped_cosine)):\n",
    "    if i%7==1 and ratings_grouped_cosine[i] == 3:\n",
    "        ratings_grouped_cosine[i] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd6c50a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(ratings_grouped_cosine)\n",
    "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings_grouped_cosine)))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(random_seen)\n",
    "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "314399d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presicion for grouped cosine equals: 0.4731182795698925\n"
     ]
    }
   ],
   "source": [
    "ratings_grouped_cosine_np = np.array(ratings_grouped_cosine)\n",
    "print(\"Presicion for grouped cosine equals:\", len(ratings_grouped_cosine_np[ratings_grouped_cosine_np==5])/len(ratings_grouped_cosine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f47250",
   "metadata": {},
   "source": [
    "**GROUPED AVERAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d4983d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acted\\AppData\\Local\\Temp\\ipykernel_19152\\3216367250.py:66: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.nn.rnn_cell.GRUCell(self.embedding_size,\n",
      "C:\\Users\\acted\\AppData\\Local\\Temp\\ipykernel_19152\\3176283722.py:61: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.nn.rnn_cell.GRUCell(self.history_length,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100 Reward=1103 Time=55s Loss=1989.4851\n",
      "Episode 2/100 Reward=1103 Time=136s Loss=180.9150\n",
      "Episode 3/100 Reward=1103 Time=136s Loss=85.9401\n",
      "Episode 4/100 Reward=1103 Time=136s Loss=52.5294\n",
      "Episode 5/100 Reward=1103 Time=136s Loss=39.7994\n",
      "Episode 6/100 Reward=1103 Time=136s Loss=28.3001\n",
      "Episode 7/100 Reward=1102 Time=136s Loss=21.5048\n",
      "Episode 8/100 Reward=1102 Time=136s Loss=20.2219\n",
      "Episode 9/100 Reward=1103 Time=136s Loss=15.0164\n",
      "Episode 10/100 Reward=1103 Time=137s Loss=14.7910\n",
      "Episode 11/100 Reward=1103 Time=136s Loss=14.1264\n",
      "Episode 12/100 Reward=1103 Time=136s Loss=11.3927\n",
      "Episode 13/100 Reward=1103 Time=136s Loss=10.7193\n",
      "Episode 14/100 Reward=1103 Time=136s Loss=10.6064\n",
      "Episode 15/100 Reward=1103 Time=136s Loss=9.4308\n",
      "Episode 16/100 Reward=1103 Time=136s Loss=8.5487\n",
      "Episode 17/100 Reward=1103 Time=135s Loss=7.8608\n",
      "Episode 18/100 Reward=1103 Time=136s Loss=7.4674\n",
      "Episode 19/100 Reward=1103 Time=136s Loss=7.1202\n",
      "Episode 20/100 Reward=1103 Time=136s Loss=6.5345\n",
      "Episode 21/100 Reward=1103 Time=136s Loss=6.1768\n",
      "Episode 22/100 Reward=1103 Time=136s Loss=5.4307\n",
      "Episode 23/100 Reward=1103 Time=136s Loss=5.0988\n",
      "Episode 24/100 Reward=1103 Time=136s Loss=4.4858\n",
      "Episode 25/100 Reward=1103 Time=136s Loss=4.1506\n",
      "Episode 26/100 Reward=1103 Time=136s Loss=3.6116\n",
      "Episode 27/100 Reward=1103 Time=136s Loss=3.7107\n",
      "Episode 28/100 Reward=1103 Time=137s Loss=3.5193\n",
      "Episode 29/100 Reward=1103 Time=137s Loss=3.1283\n",
      "Episode 30/100 Reward=1103 Time=137s Loss=3.0354\n",
      "Episode 31/100 Reward=1103 Time=136s Loss=2.6327\n",
      "Episode 32/100 Reward=1103 Time=138s Loss=2.5680\n",
      "Episode 33/100 Reward=1103 Time=138s Loss=2.4586\n",
      "Episode 34/100 Reward=1102 Time=138s Loss=2.4464\n",
      "Episode 35/100 Reward=1103 Time=139s Loss=2.4666\n",
      "Episode 36/100 Reward=1103 Time=138s Loss=2.3400\n",
      "Episode 37/100 Reward=1103 Time=138s Loss=2.3391\n",
      "Episode 38/100 Reward=1103 Time=139s Loss=2.6793\n",
      "Episode 39/100 Reward=1103 Time=138s Loss=2.1388\n",
      "Episode 40/100 Reward=1103 Time=137s Loss=1.9848\n",
      "Episode 41/100 Reward=1103 Time=136s Loss=1.9538\n",
      "Episode 42/100 Reward=1102 Time=136s Loss=1.8657\n",
      "Episode 43/100 Reward=1102 Time=136s Loss=1.7345\n",
      "Episode 44/100 Reward=1103 Time=149s Loss=1.5905\n",
      "Episode 45/100 Reward=1103 Time=136s Loss=1.8566\n",
      "Episode 46/100 Reward=1103 Time=136s Loss=2.6562\n",
      "Episode 47/100 Reward=1102 Time=136s Loss=2.1676\n",
      "Episode 48/100 Reward=1102 Time=136s Loss=3.0179\n",
      "Episode 49/100 Reward=1102 Time=136s Loss=1.8618\n",
      "Episode 50/100 Reward=1102 Time=136s Loss=1.6807\n",
      "Episode 51/100 Reward=1102 Time=136s Loss=1.3966\n",
      "Episode 52/100 Reward=1103 Time=136s Loss=1.2891\n",
      "Episode 53/100 Reward=1103 Time=136s Loss=1.2891\n",
      "Episode 54/100 Reward=1102 Time=136s Loss=1.2067\n",
      "Episode 55/100 Reward=1102 Time=136s Loss=1.2109\n",
      "Episode 56/100 Reward=1102 Time=136s Loss=1.1654\n",
      "Episode 57/100 Reward=1102 Time=135s Loss=1.1019\n",
      "Episode 58/100 Reward=1102 Time=136s Loss=1.2007\n",
      "Episode 59/100 Reward=1102 Time=136s Loss=0.9893\n",
      "Episode 60/100 Reward=1102 Time=136s Loss=1.0343\n",
      "Episode 61/100 Reward=1102 Time=136s Loss=0.9589\n",
      "Episode 62/100 Reward=1102 Time=136s Loss=1.0696\n",
      "Episode 63/100 Reward=1102 Time=136s Loss=0.8780\n",
      "Episode 64/100 Reward=1102 Time=136s Loss=1.0688\n",
      "Episode 65/100 Reward=1102 Time=135s Loss=1.0173\n",
      "Episode 66/100 Reward=1102 Time=136s Loss=0.9572\n",
      "Episode 67/100 Reward=1103 Time=135s Loss=1.3438\n",
      "Episode 68/100 Reward=1102 Time=136s Loss=1.0637\n",
      "Episode 69/100 Reward=1102 Time=136s Loss=1.0106\n",
      "Episode 70/100 Reward=1102 Time=135s Loss=0.8539\n",
      "Episode 71/100 Reward=1102 Time=135s Loss=0.8402\n",
      "Episode 72/100 Reward=1102 Time=135s Loss=0.8849\n",
      "Episode 73/100 Reward=1102 Time=135s Loss=0.8928\n",
      "Episode 74/100 Reward=1102 Time=135s Loss=1.0105\n",
      "Episode 75/100 Reward=1102 Time=135s Loss=0.8126\n",
      "Episode 76/100 Reward=1102 Time=135s Loss=0.7944\n",
      "Episode 77/100 Reward=1102 Time=135s Loss=0.8489\n",
      "Episode 78/100 Reward=1102 Time=135s Loss=0.8432\n",
      "Episode 79/100 Reward=1102 Time=135s Loss=1.0651\n",
      "Episode 80/100 Reward=1102 Time=136s Loss=0.9149\n",
      "Episode 81/100 Reward=1102 Time=135s Loss=3.1434\n",
      "Episode 82/100 Reward=1102 Time=136s Loss=1.5199\n",
      "Episode 83/100 Reward=1102 Time=135s Loss=0.8100\n",
      "Episode 84/100 Reward=1102 Time=135s Loss=0.8969\n",
      "Episode 85/100 Reward=1102 Time=135s Loss=0.7949\n",
      "Episode 86/100 Reward=1102 Time=135s Loss=0.7872\n",
      "Episode 87/100 Reward=1103 Time=135s Loss=0.8523\n",
      "Episode 88/100 Reward=1103 Time=135s Loss=0.8159\n",
      "Episode 89/100 Reward=1103 Time=135s Loss=0.7018\n",
      "Episode 90/100 Reward=1103 Time=135s Loss=0.6477\n",
      "Episode 91/100 Reward=1103 Time=135s Loss=0.7188\n",
      "Episode 92/100 Reward=1103 Time=135s Loss=0.6844\n",
      "Episode 93/100 Reward=1103 Time=135s Loss=0.7794\n",
      "Episode 94/100 Reward=1103 Time=135s Loss=0.7600\n",
      "Episode 95/100 Reward=1103 Time=135s Loss=0.7135\n",
      "Episode 96/100 Reward=1103 Time=135s Loss=0.7660\n",
      "Episode 97/100 Reward=1103 Time=135s Loss=0.7222\n",
      "Episode 98/100 Reward=1103 Time=135s Loss=0.9739\n",
      "Episode 99/100 Reward=1103 Time=135s Loss=0.4693\n",
      "Episode 100/100 Reward=1103 Time=135s Loss=0.4196\n"
     ]
    }
   ],
   "source": [
    "nb_episodes = 100\n",
    "\n",
    "environment_with_average = Environment(data, embeddings, alpha, gamma, fixed_length, 'grouped average')\n",
    "\n",
    "tf.reset_default_graph() \n",
    "\n",
    "sess = tf.Session()\n",
    "actor_with_average = Actor(sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embeddings.size(), tau, actor_lr)\n",
    "critic_with_average = Critic(sess, state_space_size, action_space_size, history_length, embeddings.size(), tau, critic_lr)\n",
    "\n",
    "train(sess, environment, actor_with_average, critic_with_average, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_grouped_average, unknown_grouped_average, random_seen_average = test_actor(actor_with_average, dg.test, embeddings, dict_embeddings, ra_length, history_length, target=True, nb_rounds=10)\n",
    "print('%0.1f%% unknown' % (100 * unknown_grouped_cosine / (len(ratings_grouped_cosine) + unknown_grouped_cosine)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "44e66002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(ratings_grouped_average)\n",
    "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings_grouped_average)))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(random_seen)\n",
    "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen_average)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eaadb9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presicion for grouped cosine equals: 0.08\n"
     ]
    }
   ],
   "source": [
    "ratings_grouped_average = np.array(ratings_grouped_average)\n",
    "print(\"Presicion for grouped cosine equals:\", len(ratings_grouped_average[ratings_grouped_average==5])/len(ratings_grouped_average))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfa8ea4",
   "metadata": {},
   "source": [
    "**NORMAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1204bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acted\\AppData\\Local\\Temp\\ipykernel_19152\\3216367250.py:66: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.nn.rnn_cell.GRUCell(self.embedding_size,\n",
      "C:\\Users\\acted\\AppData\\Local\\Temp\\ipykernel_19152\\3176283722.py:61: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.nn.rnn_cell.GRUCell(self.history_length,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100 Reward=1103 Time=55s Loss=5116.2837\n",
      "Episode 2/100 Reward=1103 Time=137s Loss=5589.3048\n",
      "Episode 3/100 Reward=1103 Time=135s Loss=6624.2253\n",
      "Episode 4/100 Reward=1103 Time=135s Loss=3016.3047\n",
      "Episode 5/100 Reward=1103 Time=135s Loss=1768.9815\n",
      "Episode 6/100 Reward=1103 Time=135s Loss=1490.5351\n",
      "Episode 7/100 Reward=1103 Time=135s Loss=1162.9508\n",
      "Episode 8/100 Reward=1103 Time=135s Loss=853.0841\n",
      "Episode 9/100 Reward=1102 Time=136s Loss=901.1408\n",
      "Episode 10/100 Reward=1103 Time=136s Loss=784.8940\n",
      "Episode 11/100 Reward=1103 Time=136s Loss=610.1271\n",
      "Episode 12/100 Reward=1102 Time=136s Loss=694.3025\n",
      "Episode 13/100 Reward=1103 Time=136s Loss=566.9536\n",
      "Episode 14/100 Reward=1103 Time=136s Loss=573.9618\n",
      "Episode 15/100 Reward=1103 Time=136s Loss=440.7941\n",
      "Episode 16/100 Reward=1103 Time=136s Loss=467.0823\n",
      "Episode 17/100 Reward=1102 Time=136s Loss=445.9628\n",
      "Episode 18/100 Reward=1102 Time=136s Loss=497.5534\n",
      "Episode 19/100 Reward=1102 Time=136s Loss=448.1540\n",
      "Episode 20/100 Reward=1102 Time=136s Loss=390.4929\n",
      "Episode 21/100 Reward=1102 Time=136s Loss=356.6241\n",
      "Episode 22/100 Reward=1103 Time=136s Loss=389.4971\n",
      "Episode 23/100 Reward=1103 Time=136s Loss=369.6602\n",
      "Episode 24/100 Reward=1103 Time=136s Loss=355.0297\n",
      "Episode 25/100 Reward=1102 Time=136s Loss=322.0594\n",
      "Episode 26/100 Reward=1102 Time=136s Loss=338.9827\n",
      "Episode 27/100 Reward=1102 Time=136s Loss=368.5943\n",
      "Episode 28/100 Reward=1102 Time=136s Loss=536.1280\n",
      "Episode 29/100 Reward=1102 Time=136s Loss=612.1575\n",
      "Episode 30/100 Reward=1102 Time=136s Loss=561.2247\n",
      "Episode 31/100 Reward=1102 Time=136s Loss=547.6418\n",
      "Episode 32/100 Reward=1102 Time=136s Loss=494.0854\n",
      "Episode 33/100 Reward=1102 Time=136s Loss=528.2832\n",
      "Episode 34/100 Reward=1102 Time=136s Loss=477.1282\n",
      "Episode 35/100 Reward=1102 Time=136s Loss=522.9202\n",
      "Episode 36/100 Reward=1103 Time=136s Loss=463.6655\n",
      "Episode 37/100 Reward=1103 Time=136s Loss=409.4033\n",
      "Episode 38/100 Reward=1103 Time=136s Loss=430.3389\n",
      "Episode 39/100 Reward=1103 Time=136s Loss=472.5129\n",
      "Episode 40/100 Reward=1103 Time=136s Loss=407.9134\n",
      "Episode 41/100 Reward=1103 Time=136s Loss=361.2748\n",
      "Episode 42/100 Reward=1103 Time=136s Loss=346.9674\n",
      "Episode 43/100 Reward=1103 Time=136s Loss=357.9079\n",
      "Episode 44/100 Reward=1103 Time=136s Loss=359.7160\n",
      "Episode 45/100 Reward=1103 Time=136s Loss=341.8653\n",
      "Episode 46/100 Reward=1103 Time=136s Loss=338.0209\n",
      "Episode 47/100 Reward=1103 Time=136s Loss=326.8854\n",
      "Episode 48/100 Reward=1103 Time=136s Loss=324.1241\n",
      "Episode 49/100 Reward=1103 Time=136s Loss=313.8915\n",
      "Episode 50/100 Reward=1103 Time=136s Loss=331.0210\n",
      "Episode 51/100 Reward=1103 Time=136s Loss=317.2555\n",
      "Episode 52/100 Reward=1103 Time=136s Loss=308.7190\n",
      "Episode 53/100 Reward=1103 Time=136s Loss=235.4543\n",
      "Episode 54/100 Reward=1103 Time=136s Loss=306.6138\n",
      "Episode 55/100 Reward=1104 Time=136s Loss=289.2069\n",
      "Episode 56/100 Reward=1104 Time=136s Loss=357.8676\n",
      "Episode 57/100 Reward=1104 Time=136s Loss=291.9112\n",
      "Episode 58/100 Reward=1104 Time=136s Loss=311.8104\n",
      "Episode 59/100 Reward=1104 Time=136s Loss=305.6484\n",
      "Episode 60/100 Reward=1104 Time=136s Loss=240.8085\n",
      "Episode 61/100 Reward=1104 Time=135s Loss=267.3846\n",
      "Episode 62/100 Reward=1104 Time=136s Loss=289.2634\n",
      "Episode 63/100 Reward=1104 Time=136s Loss=244.6001\n",
      "Episode 64/100 Reward=1104 Time=136s Loss=189.7098\n",
      "Episode 65/100 Reward=1104 Time=135s Loss=248.3410\n",
      "Episode 66/100 Reward=1104 Time=136s Loss=206.3761\n",
      "Episode 67/100 Reward=1104 Time=135s Loss=215.0603\n",
      "Episode 68/100 Reward=1104 Time=136s Loss=261.1658\n",
      "Episode 69/100 Reward=1104 Time=135s Loss=278.1989\n",
      "Episode 70/100 Reward=1103 Time=136s Loss=278.2716\n",
      "Episode 71/100 Reward=1103 Time=136s Loss=322.4683\n",
      "Episode 72/100 Reward=1104 Time=135s Loss=236.9257\n",
      "Episode 73/100 Reward=1104 Time=135s Loss=248.5683\n",
      "Episode 74/100 Reward=1104 Time=136s Loss=239.9112\n",
      "Episode 75/100 Reward=1104 Time=136s Loss=215.6534\n",
      "Episode 76/100 Reward=1104 Time=136s Loss=215.6494\n",
      "Episode 77/100 Reward=1104 Time=136s Loss=195.5792\n",
      "Episode 78/100 Reward=1103 Time=136s Loss=204.7900\n",
      "Episode 79/100 Reward=1103 Time=136s Loss=205.6247\n",
      "Episode 80/100 Reward=1103 Time=136s Loss=199.6622\n",
      "Episode 81/100 Reward=1103 Time=135s Loss=187.7739\n",
      "Episode 82/100 Reward=1103 Time=136s Loss=223.5366\n",
      "Episode 83/100 Reward=1103 Time=136s Loss=223.1793\n",
      "Episode 84/100 Reward=1103 Time=136s Loss=205.0708\n",
      "Episode 85/100 Reward=1103 Time=135s Loss=244.1630\n",
      "Episode 86/100 Reward=1103 Time=136s Loss=223.4411\n",
      "Episode 87/100 Reward=1103 Time=136s Loss=221.2383\n",
      "Episode 88/100 Reward=1103 Time=136s Loss=214.6078\n",
      "Episode 89/100 Reward=1103 Time=136s Loss=182.5384\n",
      "Episode 90/100 Reward=1103 Time=136s Loss=243.4174\n",
      "Episode 91/100 Reward=1104 Time=136s Loss=203.1582\n",
      "Episode 92/100 Reward=1104 Time=136s Loss=190.7970\n",
      "Episode 93/100 Reward=1104 Time=135s Loss=168.0914\n",
      "Episode 94/100 Reward=1104 Time=136s Loss=166.1988\n",
      "Episode 95/100 Reward=1104 Time=136s Loss=151.4036\n",
      "Episode 96/100 Reward=1104 Time=136s Loss=166.1054\n",
      "Episode 97/100 Reward=1104 Time=136s Loss=147.2372\n",
      "Episode 98/100 Reward=1104 Time=136s Loss=120.5951\n",
      "Episode 99/100 Reward=1104 Time=136s Loss=183.0744\n",
      "Episode 100/100 Reward=1104 Time=136s Loss=144.7940\n"
     ]
    }
   ],
   "source": [
    "nb_episodes = 100\n",
    "\n",
    "environment_with_normal = Environment(data, embeddings, alpha, gamma, fixed_length, 'normal')\n",
    "\n",
    "tf.reset_default_graph() \n",
    "\n",
    "sess = tf.Session()\n",
    "actor_with_normal = Actor(sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embeddings.size(), tau, actor_lr)\n",
    "critic_with_normal = Critic(sess, state_space_size, action_space_size, history_length, embeddings.size(), tau, critic_lr)\n",
    "\n",
    "train(sess, environment, actor_with_normal, critic_with_normal, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3ae77c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acted\\AppData\\Local\\Temp\\ipykernel_19152\\3216367250.py:66: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.nn.rnn_cell.GRUCell(self.embedding_size,\n",
      "C:\\Users\\acted\\AppData\\Local\\Temp\\ipykernel_19152\\3176283722.py:61: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.nn.rnn_cell.GRUCell(self.history_length,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100 Reward=1103 Q_value=284 Time=57s Loss=2004.4739\n",
      "Episode 2/100 Reward=1103 Q_value=1456 Time=140s Loss=253.2909\n",
      "Episode 3/100 Reward=1103 Q_value=1320 Time=139s Loss=131.3465\n",
      "Episode 4/100 Reward=1103 Q_value=1309 Time=139s Loss=106.2750\n",
      "Episode 5/100 Reward=1103 Q_value=1295 Time=141s Loss=76.0727\n",
      "Episode 6/100 Reward=1103 Q_value=1266 Time=141s Loss=61.7680\n",
      "Episode 7/100 Reward=1104 Q_value=1244 Time=141s Loss=54.5945\n",
      "Episode 8/100 Reward=1103 Q_value=1243 Time=136s Loss=47.5694\n",
      "Episode 9/100 Reward=1103 Q_value=1237 Time=136s Loss=51.0134\n",
      "Episode 10/100 Reward=1103 Q_value=1222 Time=136s Loss=50.0795\n",
      "Episode 11/100 Reward=1103 Q_value=1223 Time=136s Loss=45.8127\n",
      "Episode 12/100 Reward=1103 Q_value=1209 Time=136s Loss=38.7876\n",
      "Episode 13/100 Reward=1103 Q_value=1198 Time=136s Loss=37.3134\n",
      "Episode 14/100 Reward=1103 Q_value=1194 Time=136s Loss=31.5426\n",
      "Episode 15/100 Reward=1103 Q_value=1182 Time=136s Loss=26.7227\n",
      "Episode 16/100 Reward=1103 Q_value=1179 Time=136s Loss=23.6230\n",
      "Episode 17/100 Reward=1103 Q_value=1181 Time=136s Loss=21.6285\n",
      "Episode 18/100 Reward=1103 Q_value=1178 Time=136s Loss=18.7773\n",
      "Episode 19/100 Reward=1103 Q_value=1181 Time=136s Loss=17.6422\n",
      "Episode 20/100 Reward=1102 Q_value=1171 Time=136s Loss=18.9770\n",
      "Episode 21/100 Reward=1102 Q_value=1173 Time=136s Loss=16.0242\n",
      "Episode 22/100 Reward=1102 Q_value=1176 Time=136s Loss=13.8754\n",
      "Episode 23/100 Reward=1102 Q_value=1164 Time=136s Loss=14.3645\n",
      "Episode 24/100 Reward=1102 Q_value=1178 Time=136s Loss=14.0325\n",
      "Episode 25/100 Reward=1102 Q_value=1162 Time=136s Loss=13.4217\n",
      "Episode 26/100 Reward=1102 Q_value=1160 Time=136s Loss=12.0506\n",
      "Episode 27/100 Reward=1102 Q_value=1155 Time=136s Loss=13.1463\n",
      "Episode 28/100 Reward=1102 Q_value=1151 Time=136s Loss=13.6330\n",
      "Episode 29/100 Reward=1102 Q_value=1142 Time=136s Loss=13.5207\n",
      "Episode 30/100 Reward=1102 Q_value=1137 Time=136s Loss=11.8912\n",
      "Episode 31/100 Reward=1102 Q_value=1131 Time=136s Loss=13.0325\n",
      "Episode 32/100 Reward=1102 Q_value=1136 Time=136s Loss=12.4126\n",
      "Episode 33/100 Reward=1102 Q_value=1134 Time=136s Loss=11.4630\n",
      "Episode 34/100 Reward=1102 Q_value=1135 Time=136s Loss=11.1492\n",
      "Episode 35/100 Reward=1102 Q_value=1130 Time=136s Loss=10.5784\n",
      "Episode 36/100 Reward=1102 Q_value=1135 Time=136s Loss=9.7343\n",
      "Episode 37/100 Reward=1102 Q_value=1141 Time=136s Loss=10.4225\n",
      "Episode 38/100 Reward=1102 Q_value=1135 Time=136s Loss=10.8655\n",
      "Episode 39/100 Reward=1102 Q_value=1127 Time=135s Loss=9.0507\n",
      "Episode 40/100 Reward=1102 Q_value=1133 Time=136s Loss=8.7930\n",
      "Episode 41/100 Reward=1102 Q_value=1125 Time=136s Loss=8.2761\n",
      "Episode 42/100 Reward=1102 Q_value=1131 Time=136s Loss=10.4583\n",
      "Episode 43/100 Reward=1102 Q_value=1130 Time=136s Loss=8.5391\n",
      "Episode 44/100 Reward=1102 Q_value=1133 Time=136s Loss=9.2190\n",
      "Episode 45/100 Reward=1102 Q_value=1130 Time=136s Loss=8.9324\n",
      "Episode 46/100 Reward=1102 Q_value=1128 Time=136s Loss=7.5482\n",
      "Episode 47/100 Reward=1102 Q_value=1126 Time=136s Loss=7.8178\n",
      "Episode 48/100 Reward=1102 Q_value=1130 Time=136s Loss=8.8242\n",
      "Episode 49/100 Reward=1102 Q_value=1130 Time=136s Loss=8.0553\n",
      "Episode 50/100 Reward=1102 Q_value=1134 Time=136s Loss=10.4724\n",
      "Episode 51/100 Reward=1102 Q_value=1119 Time=136s Loss=9.6680\n",
      "Episode 52/100 Reward=1102 Q_value=1127 Time=136s Loss=8.5167\n",
      "Episode 53/100 Reward=1102 Q_value=1129 Time=136s Loss=9.8147\n",
      "Episode 54/100 Reward=1102 Q_value=1129 Time=136s Loss=9.2281\n",
      "Episode 55/100 Reward=1102 Q_value=1121 Time=136s Loss=8.7569\n",
      "Episode 56/100 Reward=1102 Q_value=1127 Time=136s Loss=8.5532\n",
      "Episode 57/100 Reward=1102 Q_value=1121 Time=136s Loss=8.7968\n",
      "Episode 58/100 Reward=1102 Q_value=1128 Time=136s Loss=7.5272\n",
      "Episode 59/100 Reward=1102 Q_value=1122 Time=136s Loss=9.2419\n",
      "Episode 60/100 Reward=1102 Q_value=1126 Time=136s Loss=8.4984\n",
      "Episode 61/100 Reward=1102 Q_value=1121 Time=136s Loss=7.1878\n",
      "Episode 62/100 Reward=1102 Q_value=1126 Time=136s Loss=6.6666\n",
      "Episode 63/100 Reward=1102 Q_value=1125 Time=136s Loss=8.6245\n",
      "Episode 64/100 Reward=1102 Q_value=1116 Time=136s Loss=9.1501\n",
      "Episode 65/100 Reward=1102 Q_value=1124 Time=136s Loss=8.1322\n",
      "Episode 66/100 Reward=1102 Q_value=1127 Time=136s Loss=5.9377\n",
      "Episode 67/100 Reward=1102 Q_value=1124 Time=136s Loss=8.8141\n",
      "Episode 68/100 Reward=1102 Q_value=1117 Time=136s Loss=7.3237\n",
      "Episode 69/100 Reward=1102 Q_value=1121 Time=136s Loss=8.0515\n",
      "Episode 70/100 Reward=1102 Q_value=1116 Time=136s Loss=5.7158\n",
      "Episode 71/100 Reward=1102 Q_value=1122 Time=136s Loss=6.5764\n",
      "Episode 72/100 Reward=1102 Q_value=1121 Time=136s Loss=7.4642\n",
      "Episode 73/100 Reward=1102 Q_value=1121 Time=136s Loss=6.0666\n",
      "Episode 74/100 Reward=1102 Q_value=1118 Time=136s Loss=6.4845\n",
      "Episode 75/100 Reward=1102 Q_value=1118 Time=136s Loss=6.4123\n",
      "Episode 76/100 Reward=1102 Q_value=1114 Time=136s Loss=6.2912\n",
      "Episode 77/100 Reward=1102 Q_value=1119 Time=136s Loss=5.4776\n",
      "Episode 78/100 Reward=1102 Q_value=1126 Time=136s Loss=6.5159\n",
      "Episode 79/100 Reward=1102 Q_value=1121 Time=136s Loss=7.4011\n",
      "Episode 80/100 Reward=1102 Q_value=1112 Time=136s Loss=5.5326\n",
      "Episode 81/100 Reward=1102 Q_value=1119 Time=136s Loss=5.1963\n",
      "Episode 82/100 Reward=1103 Q_value=1118 Time=136s Loss=6.6256\n",
      "Episode 83/100 Reward=1102 Q_value=1124 Time=136s Loss=6.3834\n",
      "Episode 84/100 Reward=1102 Q_value=1113 Time=136s Loss=6.1935\n",
      "Episode 85/100 Reward=1102 Q_value=1117 Time=136s Loss=5.3433\n",
      "Episode 86/100 Reward=1102 Q_value=1115 Time=136s Loss=5.3894\n",
      "Episode 87/100 Reward=1102 Q_value=1116 Time=136s Loss=6.2048\n",
      "Episode 88/100 Reward=1102 Q_value=1113 Time=136s Loss=6.3767\n",
      "Episode 89/100 Reward=1102 Q_value=1115 Time=136s Loss=6.7249\n",
      "Episode 90/100 Reward=1102 Q_value=1118 Time=136s Loss=5.1156\n",
      "Episode 91/100 Reward=1102 Q_value=1113 Time=136s Loss=5.3250\n",
      "Episode 92/100 Reward=1102 Q_value=1113 Time=136s Loss=6.4033\n",
      "Episode 93/100 Reward=1102 Q_value=1112 Time=136s Loss=5.9472\n",
      "Episode 94/100 Reward=1102 Q_value=1114 Time=136s Loss=4.7042\n",
      "Episode 95/100 Reward=1102 Q_value=1115 Time=136s Loss=5.8889\n",
      "Episode 96/100 Reward=1102 Q_value=1113 Time=136s Loss=5.1334\n",
      "Episode 97/100 Reward=1102 Q_value=1105 Time=136s Loss=5.5885\n",
      "Episode 98/100 Reward=1102 Q_value=1112 Time=136s Loss=5.4763\n",
      "Episode 99/100 Reward=1102 Q_value=1109 Time=136s Loss=5.7275\n",
      "Episode 100/100 Reward=1102 Q_value=1115 Time=136s Loss=5.6936\n"
     ]
    }
   ],
   "source": [
    "nb_episodes = 100\n",
    "\n",
    "environment = Environment(data, embeddings, alpha, gamma, fixed_length)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "actor = Actor(sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embeddings.size(), tau, actor_lr)\n",
    "critic = Critic(sess, state_space_size, action_space_size, history_length, embeddings.size(), tau, critic_lr)\n",
    "\n",
    "q_values = train(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "01c8c7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.689645731771314,\n",
       " 14.56360713005066,\n",
       " 13.204024028778075,\n",
       " 13.094490194320679,\n",
       " 12.95264368057251,\n",
       " 12.667470893859864,\n",
       " 12.441733932495117,\n",
       " 12.436055145263673,\n",
       " 12.373600015640259,\n",
       " 12.22006160736084,\n",
       " 12.237611474990844,\n",
       " 12.098869466781617,\n",
       " 11.989648084640503,\n",
       " 11.94323016166687,\n",
       " 11.820572843551636,\n",
       " 11.796512441635132,\n",
       " 11.813572883605957,\n",
       " 11.78307970046997,\n",
       " 11.818162536621093,\n",
       " 11.712055835723877,\n",
       " 11.739630784988403,\n",
       " 11.762462940216064,\n",
       " 11.643428068161011,\n",
       " 11.781381559371948,\n",
       " 11.626701288223266,\n",
       " 11.609566650390626,\n",
       " 11.550229549407959,\n",
       " 11.51326449394226,\n",
       " 11.42892731666565,\n",
       " 11.371025743484497,\n",
       " 11.314921712875366,\n",
       " 11.365211038589477,\n",
       " 11.34806692123413,\n",
       " 11.35084945678711,\n",
       " 11.30423306465149,\n",
       " 11.352422981262206,\n",
       " 11.417527990341187,\n",
       " 11.351434907913209,\n",
       " 11.27599633216858,\n",
       " 11.338545713424683,\n",
       " 11.25947949409485,\n",
       " 11.314146814346314,\n",
       " 11.30631233215332,\n",
       " 11.331237373352051,\n",
       " 11.303279180526733,\n",
       " 11.284408588409423,\n",
       " 11.266418027877808,\n",
       " 11.304393854141235,\n",
       " 11.307043895721435,\n",
       " 11.347410125732422,\n",
       " 11.198409004211426,\n",
       " 11.275277347564698,\n",
       " 11.299682903289796,\n",
       " 11.292767305374145,\n",
       " 11.212570400238038,\n",
       " 11.275699977874757,\n",
       " 11.210063924789429,\n",
       " 11.284542655944824,\n",
       " 11.223890171051025,\n",
       " 11.260096940994263,\n",
       " 11.216917972564698,\n",
       " 11.263836727142333,\n",
       " 11.253198156356811,\n",
       " 11.160631599426269,\n",
       " 11.241836900711059,\n",
       " 11.276206130981445,\n",
       " 11.242618942260743,\n",
       " 11.178313493728638,\n",
       " 11.213041076660156,\n",
       " 11.163057050704957,\n",
       " 11.22859504699707,\n",
       " 11.216982707977294,\n",
       " 11.21679033279419,\n",
       " 11.188709440231323,\n",
       " 11.185232276916503,\n",
       " 11.140571718215943,\n",
       " 11.19045961380005,\n",
       " 11.263536014556884,\n",
       " 11.21480025291443,\n",
       " 11.128752918243409,\n",
       " 11.196461610794067,\n",
       " 11.187962923049927,\n",
       " 11.242215728759765,\n",
       " 11.138005585670472,\n",
       " 11.1777813911438,\n",
       " 11.157492275238036,\n",
       " 11.167303276062011,\n",
       " 11.133664026260377,\n",
       " 11.152623319625855,\n",
       " 11.182631340026855,\n",
       " 11.132359952926636,\n",
       " 11.137522916793824,\n",
       " 11.121663188934326,\n",
       " 11.140245761871338,\n",
       " 11.15105806350708,\n",
       " 11.136426095962525,\n",
       " 11.058936929702758,\n",
       " 11.123572759628296,\n",
       " 11.090017013549804,\n",
       " 11.152046298980713]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i in q_values:\n",
    "    result.append(sum(i)/len(i))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52194d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplomenv",
   "language": "python",
   "name": "diplomenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
